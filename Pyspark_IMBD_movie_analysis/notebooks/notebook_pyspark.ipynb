{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pyspark.sql.session.SparkSession object at 0x158ef2760>\n"
     ]
    }
   ],
   "source": [
    "#Import SparkSession from pyspark.sql\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Create spark\n",
    "spark = SparkSession.builder.appName('my_imbd').getOrCreate()\n",
    "\n",
    "# Print my_spark\n",
    "print(spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pyspark.sql.session.SparkSession object at 0x158e15460>\n"
     ]
    }
   ],
   "source": [
    "#Import SparkSession from pyspark.sql\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Create spark\n",
    "spark = SparkSession.builder.appName('my_imbd').getOrCreate()\n",
    "\n",
    "# Print my_spark\n",
    "print(spark)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetching the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add 'src' directory to Python path\n",
    "src_path = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "if src_path not in sys.path:\n",
    "    sys.path.append(src_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src import datacleaning_prep as dcp\n",
    "from src import franchise_analysis as franch\n",
    "from src import kpi_analysis as kpi\n",
    "from src import visualisation as visn\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv(\"/Users/gyauk/github/labs/Pyspark_IMBD_movie_analysis/data/raw/movies.csv\", header=True, inferSchema=True)\n",
    "# df= dcp.load_data(file_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+---------------------+---------+--------------------+--------------------+------+---------+--------------+-----------------+--------------------+--------------------+----------+--------------------+--------------------+--------------------+------------+----------+-------+--------------------+--------+--------------------+--------------------+-----+------------+----------+--------------------+\n",
      "|adult|       backdrop_path|belongs_to_collection|   budget|              genres|            homepage|    id|  imdb_id|origin_country|original_language|      original_title|            overview|popularity|         poster_path|production_companies|production_countries|release_date|   revenue|runtime|    spoken_languages|  status|             tagline|               title|video|vote_average|vote_count|             credits|\n",
      "+-----+--------------------+---------------------+---------+--------------------+--------------------+------+---------+--------------+-----------------+--------------------+--------------------+----------+--------------------+--------------------+--------------------+------------+----------+-------+--------------------+--------+--------------------+--------------------+-----+------------+----------+--------------------+\n",
      "|false|/7RyHsO4yDXtBv1zU...| {'id': 86311, 'na...|356000000|[{'id': 12, 'name...|https://www.marve...|299534|tt4154796|        ['US']|               en|   Avengers: Endgame|After the devasta...|   31.7543|/ulzhLuWrPK07P1Yk...|[{'id': 420, 'log...|[{'iso_3166_1': '...|  2019-04-24|2799439100|    181|[{'english_name':...|Released|  Avenge the fallen.|   Avengers: Endgame|false|       8.237|     26241|\"{'cast': [{'adul...|\n",
      "|false|/vL5LR6WdxWPjLPFR...| {'id': 87096, 'na...|237000000|[{'id': 28, 'name...|https://www.avata...| 19995|tt0499549|        ['US']|               en|              Avatar|In the 22nd centu...|    30.968|/kyeqWdyUXW608qlY...|[{'id': 444, 'log...|[{'iso_3166_1': '...|  2009-12-15|2923706026|    162|[{'english_name':...|Released|Enter the world o...|              Avatar|false|       7.588|     32153|\"{'cast': [{'adul...|\n",
      "|false|/k6EOrckWFuz7I4z4...| {'id': 10, 'name'...|245000000|[{'id': 12, 'name...|http://www.starwa...|140607|tt2488496|        ['US']|               en|Star Wars: The Fo...|Thirty years afte...|   18.2471|/wqnLdwVXoBjKibFR...|[{'id': 1, 'logo_...|[{'iso_3166_1': '...|  2015-12-15|2068223624|    136|[{'english_name':...|Released|Every generation ...|Star Wars: The Fo...|false|       7.261|     19686|\"{'cast': [{'adul...|\n",
      "|false|/mDfJG3LC3Dqb67AZ...| {'id': 86311, 'na...|300000000|[{'id': 12, 'name...|https://www.marve...|299536|tt4154756|        ['US']|               en|Avengers: Infinit...|As the Avengers a...|   76.4397|/7WsyChQLEftFiDOV...|[{'id': 420, 'log...|[{'iso_3166_1': '...|  2018-04-25|2052415039|    149|[{'english_name':...|Released|Destiny arrives a...|Avengers: Infinit...|false|       8.235|     30421|\"{'cast': [{'adul...|\n",
      "|false|/sCzcYW9h55WcesOq...|                 null|200000000|[{'id': 18, 'name...|https://www.param...|   597|tt0120338|        ['US']|               en|             Titanic|101-year-old Rose...|   49.5297|/9xjZS2rlVxm8SFx8...|[{'id': 4, 'logo_...|[{'iso_3166_1': '...|  1997-11-18|2264162353|    194|[{'english_name':...|Released|Nothing on Earth ...|             Titanic|false|       7.906|     25904|\"{'cast': [{'adul...|\n",
      "|false|/aIGIYJTyOkEVUmEd...| {'id': 328, 'name...|150000000|[{'id': 28, 'name...|https://www.juras...|135397|tt0369610|        ['US']|               en|      Jurassic World|Twenty-two years ...|    22.183|/rhr4y79GpxQF9Isf...|[{'id': 56, 'logo...|[{'iso_3166_1': '...|  2015-06-06|1671537444|    124|[{'english_name':...|Released|   The park is open.|      Jurassic World|false|       6.693|     20645|\"{'cast': [{'adul...|\n",
      "|false|/1TUg5pO1VZ4B0Q1a...| {'id': 762512, 'n...|260000000|[{'id': 12, 'name...|https://movies.di...|420818|tt6105098|        ['US']|               en|       The Lion King|Simba idolizes hi...|   33.2421|/dzBtMocZuJbjLOXv...|[{'id': 2, 'logo_...|[{'iso_3166_1': '...|  2019-07-12|1662020819|    118|[{'english_name':...|Released|The king has retu...|       The Lion King|false|         7.1|     10314|{'cast': [{'adult...|\n",
      "|false|/9BBTo63ANSmhC4e6...| {'id': 86311, 'na...|220000000|[{'id': 878, 'nam...|https://www.marve...| 24428|tt0848228|        ['US']|               en|        The Avengers|When an unexpecte...|   47.1023|/RYMX2wcKCBAr24Uy...|[{'id': 420, 'log...|[{'iso_3166_1': '...|  2012-04-25|1518815515|    143|[{'english_name':...|Released|Some assembly req...|        The Avengers|false|       7.739|     31598|\"{'cast': [{'adul...|\n",
      "|false|/cHkhb5A4gQRK6zs6...| {'id': 9485, 'nam...|190000000|[{'id': 28, 'name...|https://www.uphe....|168259|tt2820852|        ['US']|               en|           Furious 7|Deckard Shaw seek...|   17.4112|/wurKlC3VKUgcfsn0...|[{'id': 333, 'log...|[{'iso_3166_1': '...|  2015-04-01|1515400000|    137|[{'english_name':...|Released|Vengeance hits home.|           Furious 7|false|       7.225|     10772|\"{'cast': [{'adul...|\n",
      "|false|/6YwkGolwdOMNpbTO...| {'id': 86311, 'na...|365000000|[{'id': 28, 'name...|https://www.marve...| 99861|tt2395427|        ['US']|               en|Avengers: Age of ...|When Tony Stark t...|   22.5457|/4ssDuvEDkSArWEdy...|[{'id': 420, 'log...|[{'iso_3166_1': '...|  2015-04-22|1405403694|    141|[{'english_name':...|Released| A new age has come.|Avengers: Age of ...|false|       7.271|     23365|\"{'cast': [{'adul...|\n",
      "|false|/b6ZJZHUdMEFECvGi...| {'id': 529892, 'n...|200000000|[{'id': 28, 'name...|https://www.marve...|284054|tt1825683|        ['US']|               en|       Black Panther|King T'Challa ret...|   27.4584|/uxzzxijgPIY7slzF...|[{'id': 420, 'log...|[{'iso_3166_1': '...|  2018-02-13|1349926083|    135|[{'english_name':...|Released| Long live the king.|       Black Panther|false|       7.373|     22502|\"{'cast': [{'adul...|\n",
      "|false|/n5A7brJCjejceZmH...| {'id': 1241, 'nam...|125000000|[{'id': 14, 'name...|https://www.warne...| 12445|tt1201607|        ['GB']|               en|Harry Potter and ...|Harry, Ron and He...|   23.0672|/c54HpQmuwXjHq2C9...|[{'id': 174, 'log...|[{'iso_3166_1': '...|  2011-07-12|1341511219|    130|[{'english_name':...|Released|        It all ends.|Harry Potter and ...|false|       8.087|     20962|\"{'cast': [{'adul...|\n",
      "|false|/5Iw7zQTHVRBOYpA0...| {'id': 10, 'name'...|200000000|[{'id': 12, 'name...|https://www.starw...|181808|tt2527336|        ['US']|               en|Star Wars: The La...|Rey develops her ...|    22.373|/kOVEVeg59E0wsnXm...|[{'id': 1, 'logo_...|[{'iso_3166_1': '...|  2017-12-13|1332698830|    152|[{'english_name':...|Released|Darkness rises......|Star Wars: The La...|false|         6.8|     15548|\"{'cast': [{'adul...|\n",
      "|false|/AoSZyb37ljMAxw0R...| {'id': 386382, 'n...|150000000|[{'id': 10751, 'n...|https://movies.di...|330457|tt4520988|        ['US']|               en|           Frozen II|Elsa, Anna, Krist...|   17.3078|/mINJaa34MtknCYl5...|[{'id': 2, 'logo_...|[{'iso_3166_1': '...|  2019-11-20|1453683476|    103|[{'english_name':...|Released|The past is not w...|           Frozen II|false|        7.25|      9879|\"{'cast': [{'adul...|\n",
      "|false|/6WA9stUMbIkEPxn3...| {'id': 328, 'name...|170000000|[{'id': 28, 'name...|https://www.uphe....|351286|tt4881806|        ['US']|               en|Jurassic World: F...|Three years after...|   26.5089|/270MrJNqJovumHXG...|[{'id': 56, 'logo...|[{'iso_3166_1': '...|  2018-06-06|1310466296|    129|[{'english_name':...|Released|   The park is gone.|Jurassic World: F...|false|       6.537|     12018|\"{'cast': [{'adul...|\n",
      "|false|/u2bZhH3nTf0So0UI...| {'id': 386382, 'n...|150000000|[{'id': 16, 'name...|http://movies.dis...|109445|tt2294629|        ['US']|               en|              Frozen|Young princess An...|    23.617|/m4uhSpErBKprhscl...|[{'id': 2, 'logo_...|[{'iso_3166_1': '...|  2013-11-20|1274219009|    102|[{'english_name':...|Released|Only the act of t...|              Frozen|false|       7.247|     16803|\"{'cast': [{'adul...|\n",
      "|false|/uU1Mt4JWhDvl4vKb...|                 null|160000000|[{'id': 10751, 'n...|http://movies.dis...|321612|tt2771200|        ['US']|               en|Beauty and the Beast|A live-action ada...|   37.4133|/hKegSKIDep2ewJWP...|[{'id': 2, 'logo_...|[{'iso_3166_1': '...|  2017-03-16|1266115964|    129|[{'english_name':...|Released|       Be our guest.|Beauty and the Beast|false|       6.971|     15593|\"{'cast': [{'adul...|\n",
      "|false|/mabuNsGJgRuCTuGq...| {'id': 468222, 'n...|200000000|[{'id': 28, 'name...|https://movies.di...|260513|tt3606756|        ['US']|               en|       Incredibles 2|Elastigirl spring...|    10.063|/9lFKBtaVIhP7E2Pk...|[{'id': 2, 'logo_...|[{'iso_3166_1': '...|  2018-06-14|1242805359|    118|[{'english_name':...|Released|It's been too lon...|       Incredibles 2|false|       7.454|     13031|\"{'cast': [{'adul...|\n",
      "+-----+--------------------+---------------------+---------+--------------------+--------------------+------+---------+--------------+-----------------+--------------------+--------------------+----------+--------------------+--------------------+--------------------+------------+----------+-------+--------------------+--------+--------------------+--------------------+-----+------------+----------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- adult: boolean (nullable = true)\n",
      " |-- backdrop_path: string (nullable = true)\n",
      " |-- belongs_to_collection: string (nullable = true)\n",
      " |-- budget: integer (nullable = true)\n",
      " |-- genres: string (nullable = true)\n",
      " |-- homepage: string (nullable = true)\n",
      " |-- id: integer (nullable = true)\n",
      " |-- imdb_id: string (nullable = true)\n",
      " |-- origin_country: string (nullable = true)\n",
      " |-- original_language: string (nullable = true)\n",
      " |-- original_title: string (nullable = true)\n",
      " |-- overview: string (nullable = true)\n",
      " |-- popularity: double (nullable = true)\n",
      " |-- poster_path: string (nullable = true)\n",
      " |-- production_companies: string (nullable = true)\n",
      " |-- production_countries: string (nullable = true)\n",
      " |-- release_date: date (nullable = true)\n",
      " |-- revenue: long (nullable = true)\n",
      " |-- runtime: integer (nullable = true)\n",
      " |-- spoken_languages: string (nullable = true)\n",
      " |-- status: string (nullable = true)\n",
      " |-- tagline: string (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- video: boolean (nullable = true)\n",
      " |-- vote_average: double (nullable = true)\n",
      " |-- vote_count: integer (nullable = true)\n",
      " |-- credits: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------------+\n",
      "|               title|avg(vote_count)|\n",
      "+--------------------+---------------+\n",
      "|           Furious 7|        10772.0|\n",
      "|       Incredibles 2|        13031.0|\n",
      "|              Avatar|        32153.0|\n",
      "|       The Lion King|        10314.0|\n",
      "|           Frozen II|         9879.0|\n",
      "|Star Wars: The Fo...|        19686.0|\n",
      "|Beauty and the Beast|        15593.0|\n",
      "|Jurassic World: F...|        12018.0|\n",
      "|      Jurassic World|        20645.0|\n",
      "|        The Avengers|        31598.0|\n",
      "|Harry Potter and ...|        20962.0|\n",
      "|Star Wars: The La...|        15548.0|\n",
      "|       Black Panther|        22502.0|\n",
      "|Avengers: Infinit...|        30421.0|\n",
      "|Avengers: Age of ...|        23365.0|\n",
      "|              Frozen|        16803.0|\n",
      "|   Avengers: Endgame|        26241.0|\n",
      "|             Titanic|        25904.0|\n",
      "+--------------------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy('title').agg({'vote_count':'avg'}).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Select and show only the name and age columns\n",
    "# df.select(\"name\", \"age\").show()\n",
    "# # Filter on age > 30\n",
    "# df.filter(df[\"age\"] > 30).show()\n",
    "# # Use Where to filter match a specific value\n",
    "# df.where(df[\"age\"] == 30).show()\n",
    "# #drop missing values\n",
    "# df.na.drop().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation & Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop Irrelevant Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------------------+---------+--------------------+------+--------------+-----------------+--------------------+----------+--------------------+--------------------+--------------------+------------+----------+-------+--------------------+--------+--------------------+--------------------+------------+----------+--------------------+\n",
      "|       backdrop_path|belongs_to_collection|   budget|              genres|    id|origin_country|original_language|            overview|popularity|         poster_path|production_companies|production_countries|release_date|   revenue|runtime|    spoken_languages|  status|             tagline|               title|vote_average|vote_count|             credits|\n",
      "+--------------------+---------------------+---------+--------------------+------+--------------+-----------------+--------------------+----------+--------------------+--------------------+--------------------+------------+----------+-------+--------------------+--------+--------------------+--------------------+------------+----------+--------------------+\n",
      "|/7RyHsO4yDXtBv1zU...| {'id': 86311, 'na...|356000000|[{'id': 12, 'name...|299534|        ['US']|               en|After the devasta...|   31.7543|/ulzhLuWrPK07P1Yk...|[{'id': 420, 'log...|[{'iso_3166_1': '...|  2019-04-24|2799439100|    181|[{'english_name':...|Released|  Avenge the fallen.|   Avengers: Endgame|       8.237|     26241|\"{'cast': [{'adul...|\n",
      "|/vL5LR6WdxWPjLPFR...| {'id': 87096, 'na...|237000000|[{'id': 28, 'name...| 19995|        ['US']|               en|In the 22nd centu...|    30.968|/kyeqWdyUXW608qlY...|[{'id': 444, 'log...|[{'iso_3166_1': '...|  2009-12-15|2923706026|    162|[{'english_name':...|Released|Enter the world o...|              Avatar|       7.588|     32153|\"{'cast': [{'adul...|\n",
      "|/k6EOrckWFuz7I4z4...| {'id': 10, 'name'...|245000000|[{'id': 12, 'name...|140607|        ['US']|               en|Thirty years afte...|   18.2471|/wqnLdwVXoBjKibFR...|[{'id': 1, 'logo_...|[{'iso_3166_1': '...|  2015-12-15|2068223624|    136|[{'english_name':...|Released|Every generation ...|Star Wars: The Fo...|       7.261|     19686|\"{'cast': [{'adul...|\n",
      "|/mDfJG3LC3Dqb67AZ...| {'id': 86311, 'na...|300000000|[{'id': 12, 'name...|299536|        ['US']|               en|As the Avengers a...|   76.4397|/7WsyChQLEftFiDOV...|[{'id': 420, 'log...|[{'iso_3166_1': '...|  2018-04-25|2052415039|    149|[{'english_name':...|Released|Destiny arrives a...|Avengers: Infinit...|       8.235|     30421|\"{'cast': [{'adul...|\n",
      "|/sCzcYW9h55WcesOq...|                 null|200000000|[{'id': 18, 'name...|   597|        ['US']|               en|101-year-old Rose...|   49.5297|/9xjZS2rlVxm8SFx8...|[{'id': 4, 'logo_...|[{'iso_3166_1': '...|  1997-11-18|2264162353|    194|[{'english_name':...|Released|Nothing on Earth ...|             Titanic|       7.906|     25904|\"{'cast': [{'adul...|\n",
      "+--------------------+---------------------+---------+--------------------+------+--------------+-----------------+--------------------+----------+--------------------+--------------------+--------------------+------------+----------+-------+--------------------+--------+--------------------+--------------------+------------+----------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df= df.drop('adult', 'imdb_id', 'original_title', 'video', 'homepage')\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "backdrop_path: <class 'pyspark.sql.column.Column'>\n",
      "belongs_to_collection: <class 'pyspark.sql.column.Column'>\n",
      "budget: <class 'pyspark.sql.column.Column'>\n",
      "genres: <class 'pyspark.sql.column.Column'>\n",
      "id: <class 'pyspark.sql.column.Column'>\n",
      "origin_country: <class 'pyspark.sql.column.Column'>\n",
      "original_language: <class 'pyspark.sql.column.Column'>\n",
      "overview: <class 'pyspark.sql.column.Column'>\n",
      "popularity: <class 'pyspark.sql.column.Column'>\n",
      "poster_path: <class 'pyspark.sql.column.Column'>\n",
      "production_companies: <class 'pyspark.sql.column.Column'>\n",
      "production_countries: <class 'pyspark.sql.column.Column'>\n",
      "release_date: <class 'pyspark.sql.column.Column'>\n",
      "revenue: <class 'pyspark.sql.column.Column'>\n",
      "runtime: <class 'pyspark.sql.column.Column'>\n",
      "spoken_languages: <class 'pyspark.sql.column.Column'>\n",
      "status: <class 'pyspark.sql.column.Column'>\n",
      "tagline: <class 'pyspark.sql.column.Column'>\n",
      "title: <class 'pyspark.sql.column.Column'>\n",
      "vote_average: <class 'pyspark.sql.column.Column'>\n",
      "vote_count: <class 'pyspark.sql.column.Column'>\n",
      "credits: <class 'pyspark.sql.column.Column'>\n"
     ]
    }
   ],
   "source": [
    "for col in df.columns:\n",
    "    print(f\"{col}: {type(df[col].iloc[0])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+\n",
      "|belongs_to_collection|\n",
      "+---------------------+\n",
      "| {'id': 86311, 'na...|\n",
      "| {'id': 87096, 'na...|\n",
      "| {'id': 10, 'name'...|\n",
      "| {'id': 86311, 'na...|\n",
      "|                 null|\n",
      "+---------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(df[1]).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- backdrop_path: string (nullable = true)\n",
      " |-- belongs_to_collection: string (nullable = true)\n",
      " |-- budget: integer (nullable = true)\n",
      " |-- genres: string (nullable = true)\n",
      " |-- id: integer (nullable = true)\n",
      " |-- origin_country: string (nullable = true)\n",
      " |-- original_language: string (nullable = true)\n",
      " |-- overview: string (nullable = true)\n",
      " |-- popularity: double (nullable = true)\n",
      " |-- poster_path: string (nullable = true)\n",
      " |-- production_companies: string (nullable = true)\n",
      " |-- production_countries: string (nullable = true)\n",
      " |-- release_date: date (nullable = true)\n",
      " |-- revenue: long (nullable = true)\n",
      " |-- runtime: integer (nullable = true)\n",
      " |-- spoken_languages: string (nullable = true)\n",
      " |-- status: string (nullable = true)\n",
      " |-- tagline: string (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- vote_average: double (nullable = true)\n",
      " |-- vote_count: integer (nullable = true)\n",
      " |-- credits: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(production_companies=\"[{'id': 444, 'logo_path': None, 'name': 'Dune Entertainment', 'origin_country': 'US'}, {'id': 574, 'logo_path': '/nLNW1TeFUYU0M5U0qmYUzOIwlB6.png', 'name': 'Lightstorm Entertainment', 'origin_country': 'US'}, {'id': 25, 'logo_path': '/qZCc1lty5FzX30aOCVRBLzaVmcp.png', 'name': '20th Century Fox', 'origin_country': 'US'}, {'id': 290, 'logo_path': '/jrgCuaQsY9ouP5ILZf4Dq4ZOkIX.png', 'name': 'Ingenious Media', 'origin_country': 'GB'}]\")"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df.select(\"production_countries\").show(truncate=False, vertical=True)  \n",
    "df.select(\"production_companies\").collect()[1]\n",
    "# from pprint import pprint\n",
    "\n",
    "# row_value = df.select(\"production_countries\").collect()[1]\n",
    "# pprint(row_value.asDict())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate JSON Like column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[backdrop_path: string, belongs_to_collection: struct<id:string,name:string,poster_path:string,backdrop_path:string>, budget: int, genres: array<struct<id:string,name:string>>, id: int, origin_country: string, original_language: string, overview: string, popularity: double, poster_path: string, production_companies: array<struct<id:string,logo_path:string,name:string,origin_country:string>>, production_countries: array<struct<iso_3166_1:string,name:string>>, release_date: date, revenue: bigint, runtime: int, spoken_languages: array<struct<english_name:string,iso_639_1:string,name:string>>, status: string, tagline: string, title: string, vote_average: double, vote_count: int, credits: string, collection_name: string, Genre names: string, Spoken languages: string, Production companies: string, Production countries: string]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 🧼 Step 2: Fix and parse JSON columns\n",
    "df = dcp.parse_json_columns(df)\n",
    "#  [\"belongs_to_collection\", \"genres\", \"spoken_languages\", \"production_companies\", \"production_countries\"]:\n",
    "# 🔍 Step 3: Extract key fields (like genre names, company names, etc.)\n",
    "dcp.extract_and_clean_columns(df)\n",
    "\n",
    "\n",
    "# df.show(5)\n",
    "# # 🧾 Step 4: Inspect columns\n",
    "# dcp.inspect_column_counts(df, \"collection_name\")\n",
    "# # dcp.inspect_column_counts(df, \"Genre names\")\n",
    "# dcp.inspect_column_counts(df, \"Production companies\")\n",
    "# dcp.inspect_column_counts(df, \"Spoken languages\")\n",
    "# dcp.inspect_column_counts(df, \"Production countries\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------------------+---------+--------------------+------+--------------+-----------------+--------------------+----------+--------------------+--------------------+--------------------+------------+----------+-------+--------------------+--------+--------------------+--------------------+------------+----------+--------------------+\n",
      "|       backdrop_path|belongs_to_collection|   budget|              genres|    id|origin_country|original_language|            overview|popularity|         poster_path|production_companies|production_countries|release_date|   revenue|runtime|    spoken_languages|  status|             tagline|               title|vote_average|vote_count|             credits|\n",
      "+--------------------+---------------------+---------+--------------------+------+--------------+-----------------+--------------------+----------+--------------------+--------------------+--------------------+------------+----------+-------+--------------------+--------+--------------------+--------------------+------------+----------+--------------------+\n",
      "|/7RyHsO4yDXtBv1zU...| {86311, The Aveng...|356000000|[{12, Adventure},...|299534|        ['US']|               en|After the devasta...|   31.7543|/ulzhLuWrPK07P1Yk...|[{420, /hUzeosd33...|[{US, United Stat...|  2019-04-24|2799439100|    181|[{English, en, En...|Released|  Avenge the fallen.|   Avengers: Endgame|       8.237|     26241|\"{'cast': [{'adul...|\n",
      "|/vL5LR6WdxWPjLPFR...| {87096, Avatar Co...|237000000|[{28, Action}, {1...| 19995|        ['US']|               en|In the 22nd centu...|    30.968|/kyeqWdyUXW608qlY...|                null|[{US, United Stat...|  2009-12-15|2923706026|    162|[{English, en, En...|Released|Enter the world o...|              Avatar|       7.588|     32153|\"{'cast': [{'adul...|\n",
      "|/k6EOrckWFuz7I4z4...| {10, Star Wars Co...|245000000|[{12, Adventure},...|140607|        ['US']|               en|Thirty years afte...|   18.2471|/wqnLdwVXoBjKibFR...|[{1, /tlVSws0Rvvt...|[{US, United Stat...|  2015-12-15|2068223624|    136|[{English, en, En...|Released|Every generation ...|Star Wars: The Fo...|       7.261|     19686|\"{'cast': [{'adul...|\n",
      "|/mDfJG3LC3Dqb67AZ...| {86311, The Aveng...|300000000|[{12, Adventure},...|299536|        ['US']|               en|As the Avengers a...|   76.4397|/7WsyChQLEftFiDOV...|[{420, /hUzeosd33...|[{US, United Stat...|  2018-04-25|2052415039|    149|[{English, en, En...|Released|Destiny arrives a...|Avengers: Infinit...|       8.235|     30421|\"{'cast': [{'adul...|\n",
      "|/sCzcYW9h55WcesOq...|                 null|200000000|[{18, Drama}, {10...|   597|        ['US']|               en|101-year-old Rose...|   49.5297|/9xjZS2rlVxm8SFx8...|[{4, /gz66EfNoYPq...|[{US, United Stat...|  1997-11-18|2264162353|    194|[{English, en, En...|Released|Nothing on Earth ...|             Titanic|       7.906|     25904|\"{'cast': [{'adul...|\n",
      "|/aIGIYJTyOkEVUmEd...| {328, Jurassic Pa...|150000000|[{28, Action}, {1...|135397|        ['US']|               en|Twenty-two years ...|    22.183|/rhr4y79GpxQF9Isf...|[{56, /cEaxANEisC...|[{US, United Stat...|  2015-06-06|1671537444|    124|[{English, en, En...|Released|   The park is open.|      Jurassic World|       6.693|     20645|\"{'cast': [{'adul...|\n",
      "|/1TUg5pO1VZ4B0Q1a...| {762512, The Lion...|260000000|[{12, Adventure},...|420818|        ['US']|               en|Simba idolizes hi...|   33.2421|/dzBtMocZuJbjLOXv...|[{2, /wdrCwmRnLFJ...|[{US, United Stat...|  2019-07-12|1662020819|    118|[{English, en, En...|Released|The king has retu...|       The Lion King|         7.1|     10314|{'cast': [{'adult...|\n",
      "|/9BBTo63ANSmhC4e6...| {86311, The Aveng...|220000000|[{878, Science Fi...| 24428|        ['US']|               en|When an unexpecte...|   47.1023|/RYMX2wcKCBAr24Uy...|[{420, /hUzeosd33...|[{US, United Stat...|  2012-04-25|1518815515|    143|[{English, en, En...|Released|Some assembly req...|        The Avengers|       7.739|     31598|\"{'cast': [{'adul...|\n",
      "|/cHkhb5A4gQRK6zs6...| {9485, The Fast a...|190000000|[{28, Action}, {5...|168259|        ['US']|               en|Deckard Shaw seek...|   17.4112|/wurKlC3VKUgcfsn0...|[{333, /5xUJfzPZ8...|[{US, United Stat...|  2015-04-01|1515400000|    137|[{Arabic, ar, الع...|Released|Vengeance hits home.|           Furious 7|       7.225|     10772|\"{'cast': [{'adul...|\n",
      "|/6YwkGolwdOMNpbTO...| {86311, The Aveng...|365000000|[{28, Action}, {1...| 99861|        ['US']|               en|When Tony Stark t...|   22.5457|/4ssDuvEDkSArWEdy...|[{420, /hUzeosd33...|[{US, United Stat...|  2015-04-22|1405403694|    141|[{English, en, En...|Released| A new age has come.|Avengers: Age of ...|       7.271|     23365|\"{'cast': [{'adul...|\n",
      "|/b6ZJZHUdMEFECvGi...| {529892, Black Pa...|200000000|[{28, Action}, {1...|284054|        ['US']|               en|King T'Challa ret...|   27.4584|/uxzzxijgPIY7slzF...|[{420, /hUzeosd33...|[{US, United Stat...|  2018-02-13|1349926083|    135|[{English, en, En...|Released| Long live the king.|       Black Panther|       7.373|     22502|\"{'cast': [{'adul...|\n",
      "|/n5A7brJCjejceZmH...| {1241, Harry Pott...|125000000|[{14, Fantasy}, {...| 12445|        ['GB']|               en|Harry, Ron and He...|   23.0672|/c54HpQmuwXjHq2C9...|[{174, /zhD3hhtKB...|[{GB, United King...|  2011-07-12|1341511219|    130|[{English, en, En...|Released|        It all ends.|Harry Potter and ...|       8.087|     20962|\"{'cast': [{'adul...|\n",
      "|/5Iw7zQTHVRBOYpA0...| {10, Star Wars Co...|200000000|[{12, Adventure},...|181808|        ['US']|               en|Rey develops her ...|    22.373|/kOVEVeg59E0wsnXm...|[{1, /tlVSws0Rvvt...|[{US, United Stat...|  2017-12-13|1332698830|    152|[{English, en, En...|Released|Darkness rises......|Star Wars: The La...|         6.8|     15548|\"{'cast': [{'adul...|\n",
      "|/AoSZyb37ljMAxw0R...| {386382, Frozen C...|150000000|[{10751, Family},...|330457|        ['US']|               en|Elsa, Anna, Krist...|   17.3078|/mINJaa34MtknCYl5...|[{2, /wdrCwmRnLFJ...|[{US, United Stat...|  2019-11-20|1453683476|    103|[{English, en, En...|Released|The past is not w...|           Frozen II|        7.25|      9879|\"{'cast': [{'adul...|\n",
      "|/6WA9stUMbIkEPxn3...| {328, Jurassic Pa...|170000000|[{28, Action}, {1...|351286|        ['US']|               en|Three years after...|   26.5089|/270MrJNqJovumHXG...|[{56, /cEaxANEisC...|[{US, United Stat...|  2018-06-06|1310466296|    129|[{English, en, En...|Released|   The park is gone.|Jurassic World: F...|       6.537|     12018|\"{'cast': [{'adul...|\n",
      "|/u2bZhH3nTf0So0UI...| {386382, Frozen C...|150000000|[{16, Animation},...|109445|        ['US']|               en|Young princess An...|    23.617|/m4uhSpErBKprhscl...|[{2, /wdrCwmRnLFJ...|[{US, United Stat...|  2013-11-20|1274219009|    102|[{English, en, En...|Released|Only the act of t...|              Frozen|       7.247|     16803|\"{'cast': [{'adul...|\n",
      "|/uU1Mt4JWhDvl4vKb...|                 null|160000000|[{10751, Family},...|321612|        ['US']|               en|A live-action ada...|   37.4133|/hKegSKIDep2ewJWP...|[{2, /wdrCwmRnLFJ...|[{US, United Stat...|  2017-03-16|1266115964|    129|[{English, en, En...|Released|       Be our guest.|Beauty and the Beast|       6.971|     15593|\"{'cast': [{'adul...|\n",
      "|/mabuNsGJgRuCTuGq...| {468222, The Incr...|200000000|[{28, Action}, {1...|260513|        ['US']|               en|Elastigirl spring...|    10.063|/9lFKBtaVIhP7E2Pk...|[{2, /wdrCwmRnLFJ...|[{US, United Stat...|  2018-06-14|1242805359|    118|[{English, en, En...|Released|It's been too lon...|       Incredibles 2|       7.454|     13031|\"{'cast': [{'adul...|\n",
      "+--------------------+---------------------+---------+--------------------+------+--------------+-----------------+--------------------+----------+--------------------+--------------------+--------------------+------------+----------+-------+--------------------+--------+--------------------+--------------------+------------+----------+--------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/04/21 16:01:21 WARN HeartbeatReceiver: Removing executor driver with no recent heartbeats: 300973 ms exceeds timeout 120000 ms\n",
      "25/04/21 16:01:21 WARN SparkContext: Killing executors is not supported by current scheduler.\n",
      "25/04/21 16:01:23 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.100.6:60760\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "25/04/21 16:01:23 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.100.6:60760\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "25/04/21 16:01:33 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.100.6:60760\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/21 16:01:33 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.100.6:60760\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/21 16:01:43 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.100.6:60760\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/21 16:01:43 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.100.6:60760\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/21 17:38:38 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.100.6:60760\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "25/04/21 17:38:38 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.100.6:60760\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "25/04/21 17:38:48 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.100.6:60760\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/21 17:38:48 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.100.6:60760\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/21 17:38:58 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.100.6:60760\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/21 17:38:58 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.100.6:60760\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/21 17:39:08 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.100.6:60760\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/21 17:39:08 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.100.6:60760\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/21 17:54:43 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.100.6:60760\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/21 17:54:43 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.100.6:60760\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/21 17:54:53 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.100.6:60760\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/21 17:54:53 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.100.6:60760\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/21 17:55:28 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.100.6:60760\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/21 17:55:28 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.100.6:60760\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/21 17:55:38 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.100.6:60760\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/21 17:55:38 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.100.6:60760\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/21 17:55:48 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.100.6:60760\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "25/04/21 17:55:48 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.100.6:60760\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "25/04/21 17:57:25 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.100.6:60760\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/21 17:57:25 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.100.6:60760\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/21 17:57:35 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.100.6:60760\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/21 17:57:35 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.100.6:60760\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/21 17:57:45 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.100.6:60760\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "25/04/21 17:57:45 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.100.6:60760\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "25/04/21 17:57:55 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.100.6:60760\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "25/04/21 17:57:55 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.100.6:60760\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "25/04/21 17:58:05 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.100.6:60760\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/21 17:58:05 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.100.6:60760\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/21 18:12:38 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.100.6:60760\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "25/04/21 18:12:38 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.100.6:60760\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "25/04/21 18:12:48 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.100.6:60760\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/21 18:12:48 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.100.6:60760\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/21 18:12:58 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.100.6:60760\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/21 18:12:58 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.100.6:60760\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/21 18:13:08 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.100.6:60760\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "25/04/21 18:13:08 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.100.6:60760\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "25/04/21 18:14:06 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.100.6:60760\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "25/04/21 18:14:06 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.100.6:60760\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "25/04/21 18:14:15 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.100.6:60760\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/21 18:14:15 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.100.6:60760\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/21 18:14:25 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.100.6:60760\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/21 18:14:25 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.100.6:60760\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/21 18:14:35 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.100.6:60760\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/21 18:14:35 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.100.6:60760\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/21 18:14:45 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.100.6:60760\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/21 18:14:45 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.100.6:60760\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/21 20:14:55 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.100.6:60760\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "25/04/21 20:14:55 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.100.6:60760\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "25/04/21 20:15:05 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.100.6:60760\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "25/04/21 20:15:05 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.100.6:60760\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "25/04/21 20:15:15 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.100.6:60760\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/21 20:15:15 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.100.6:60760\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/21 20:15:25 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.100.6:60760\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/21 20:15:25 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.100.6:60760\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/21 20:20:21 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.100.6:60760\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/21 20:20:21 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.100.6:60760\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/21 20:20:31 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.100.6:60760\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/21 20:20:31 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.100.6:60760\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/21 20:20:41 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.100.6:60760\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/21 20:20:41 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.100.6:60760\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/21 21:16:00 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.100.6:60760\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/21 21:16:00 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.100.6:60760\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/21 21:16:10 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.100.6:60760\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/21 21:16:10 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.100.6:60760\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/21 21:16:20 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.100.6:60760\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/21 21:16:20 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.100.6:60760\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/21 21:16:30 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.100.6:60760\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/21 21:16:30 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.100.6:60760\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/21 22:16:44 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.100.6:60760\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/21 22:16:44 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.100.6:60760\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/21 22:16:54 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.100.6:60760\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/21 22:16:54 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.100.6:60760\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/21 22:17:04 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.100.6:60760\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/21 22:17:04 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.100.6:60760\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/21 22:17:14 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.100.6:60760\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/21 22:17:14 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.100.6:60760\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/21 22:17:24 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.100.6:60760\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/21 22:17:24 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.100.6:60760\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/21 22:26:00 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.100.6:60760\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/21 22:26:00 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.100.6:60760\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/21 22:26:10 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.100.6:60760\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/21 22:26:10 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.100.6:60760\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/21 22:26:20 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.100.6:60760\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/21 22:26:20 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.100.6:60760\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/21 22:26:30 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.100.6:60760\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "25/04/21 22:26:30 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.100.6:60760\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "25/04/21 23:17:44 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.100.6:60760\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/21 23:17:44 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.100.6:60760\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/21 23:17:54 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.100.6:60760\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "25/04/21 23:17:54 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.100.6:60760\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "25/04/21 23:18:04 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.100.6:60760\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/21 23:18:04 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.100.6:60760\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/21 23:18:14 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.100.6:60760\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/21 23:18:14 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.100.6:60760\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/21 23:18:24 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.100.6:60760\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/21 23:18:24 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.100.6:60760\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/21 23:39:32 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.100.6:60760\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/21 23:39:32 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.100.6:60760\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/21 23:39:42 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.100.6:60760\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/21 23:39:42 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.100.6:60760\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/21 23:39:52 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.100.6:60760\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "25/04/21 23:39:52 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.100.6:60760\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "25/04/21 23:40:02 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.100.6:60760\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/21 23:40:02 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.100.6:60760\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/22 00:00:01 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.100.6:60760\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/22 00:00:01 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.100.6:60760\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/22 00:00:11 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.100.6:60760\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/22 00:00:11 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.100.6:60760\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/22 00:00:21 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.100.6:60760\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/22 00:00:21 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.100.6:60760\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/22 00:00:31 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.100.6:60760\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/22 00:00:31 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.100.6:60760\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/22 00:18:50 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.100.6:60760\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/22 00:18:50 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.100.6:60760\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/22 00:18:50 ERROR Executor: Exit as unable to send heartbeats to driver more than 60 times\n"
     ]
    }
   ],
   "source": [
    "df.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 21:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------------+-----------------------------------+------------+-------------+\n",
      "|title                                       |collection_name                    |company_name|language_name|\n",
      "+--------------------------------------------+-----------------------------------+------------+-------------+\n",
      "|Avengers: Endgame                           |The Avengers Collection            |null        |null         |\n",
      "|Avatar                                      |Avatar Collection                  |null        |null         |\n",
      "|Star Wars: The Force Awakens                |Star Wars Collection               |null        |null         |\n",
      "|Avengers: Infinity War                      |The Avengers Collection            |null        |null         |\n",
      "|Titanic                                     |null                               |null        |null         |\n",
      "|Jurassic World                              |Jurassic Park Collection           |null        |null         |\n",
      "|The Lion King                               |The Lion King (Reboot) Collection  |null        |null         |\n",
      "|The Avengers                                |The Avengers Collection            |null        |null         |\n",
      "|Furious 7                                   |The Fast and the Furious Collection|null        |null         |\n",
      "|Avengers: Age of Ultron                     |The Avengers Collection            |null        |null         |\n",
      "|Black Panther                               |Black Panther Collection           |null        |null         |\n",
      "|Harry Potter and the Deathly Hallows: Part 2|Harry Potter Collection            |null        |null         |\n",
      "|Star Wars: The Last Jedi                    |Star Wars Collection               |null        |null         |\n",
      "|Frozen II                                   |Frozen Collection                  |null        |null         |\n",
      "|Jurassic World: Fallen Kingdom              |Jurassic Park Collection           |null        |null         |\n",
      "|Frozen                                      |Frozen Collection                  |null        |null         |\n",
      "|Beauty and the Beast                        |null                               |null        |null         |\n",
      "|Incredibles 2                               |The Incredibles Collection         |null        |null         |\n",
      "+--------------------------------------------+-----------------------------------+------------+-------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# from datacleaning_prep import parse_json_columns\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType\n",
    "\n",
    "# Define your schemas\n",
    "collection_schema = StructType([\n",
    "    StructField(\"id\", IntegerType(), True),\n",
    "    StructField(\"name\", StringType(), True),\n",
    "    StructField(\"poster_path\", StringType(), True),\n",
    "    StructField(\"backdrop_path\", StringType(), True)\n",
    "])\n",
    "\n",
    "\n",
    "genre_schema = StructType([\n",
    "    StructField(\"id\", IntegerType(), True),\n",
    "    StructField(\"name\", StringType(), True)\n",
    "])\n",
    "\n",
    "production_country_schema = StructType([\n",
    "    StructField(\"name\", StringType(), True),\n",
    "    StructField(\"iso_3166_1\", IntegerType(), True)\n",
    "])\n",
    "\n",
    "production_company_schema = StructType([\n",
    "    StructField(\"id\", IntegerType(), True),\n",
    "    StructField(\"logo_path\", StringType(), True),\n",
    "    StructField(\"name\", StringType(), True),\n",
    "    StructField(\"origin_country\", StringType(), True)\n",
    "])\n",
    "\n",
    "spoken_languages_schema = StructType([\n",
    "    StructField(\"english_name\", StringType(), True),\n",
    "    StructField(\"iso_3166_1\", StringType(), True),\n",
    "    StructField(\"name\", StringType(), True)    \n",
    "])\n",
    "\n",
    "# Map columns to schemas\n",
    "columns_and_schemas = {\n",
    "    \"belongs_to_collection\": collection_schema,\n",
    "    \"genres\":genre_schema,\n",
    "    \"production_countries\":production_country_schema,\n",
    "    \"production_companies\": production_company_schema,\n",
    "    \"spoken_languages\": spoken_languages_schema\n",
    "}\n",
    "\n",
    "# Apply the helper function\n",
    "df_parsed = dcp.parse_json_columns(df, columns_and_schemas)\n",
    "\n",
    "# # Use the new struct columns\n",
    "# df_parsed.select(\n",
    "#     \"title\",\n",
    "#     \"belongs_to_collection_struct.name\",\n",
    "#     \"production_company_struct.name\",\n",
    "#     \"spoken_languages_struct.name\"\n",
    "# ).show(truncate=False)\n",
    "\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "df_parsed.select(\n",
    "    col(\"title\"),\n",
    "    col(\"belongs_to_collection_struct.name\").alias(\"collection_name\"),\n",
    "    col(\"production_companies_struct.name\").alias(\"company_name\"),\n",
    "    col(\"spoken_languages_struct.name\").alias(\"language_name\")\n",
    ").show(truncate=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 16:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+--------------------+--------------------+\n",
      "|    id|                name|         poster_path|       backdrop_path|\n",
      "+------+--------------------+--------------------+--------------------+\n",
      "|299534|The Avengers Coll...|/yFSIUVTCvgYrpalU...|/zuW6fOiusv4X9nnW...|\n",
      "| 19995|   Avatar Collection|/3C5brXxnBxfkeKWw...|/gxnvX9kF7RRUQYvB...|\n",
      "|140607|Star Wars Collection|/aSrMJYmQX8kpF26L...|/zZDkgOmFMVYpGAkR...|\n",
      "|299536|The Avengers Coll...|/yFSIUVTCvgYrpalU...|/zuW6fOiusv4X9nnW...|\n",
      "|   597|                null|                null|                null|\n",
      "|135397|Jurassic Park Col...|/qIm2nHXLpBBdMxi8...|/njFixYzIxX8jsn6K...|\n",
      "|420818|The Lion King (Re...|/dGpIRn4Nqi63JO1R...|/1KeXF239BkqLChcA...|\n",
      "| 24428|The Avengers Coll...|/yFSIUVTCvgYrpalU...|/zuW6fOiusv4X9nnW...|\n",
      "|168259|The Fast and the ...|/zOCnMPoUxgJK1RFP...|/z5A5W3WYJc3UVEWl...|\n",
      "| 99861|The Avengers Coll...|/yFSIUVTCvgYrpalU...|/zuW6fOiusv4X9nnW...|\n",
      "|284054|Black Panther Col...|/VtMkk2s92SnDUt8e...|/nsiBzWsmmerBMuD8...|\n",
      "| 12445|Harry Potter Coll...|/s4hXqX1VyWMc2ctJ...|/kmEsQL2vOTA0jnM2...|\n",
      "|181808|Star Wars Collection|/aSrMJYmQX8kpF26L...|/zZDkgOmFMVYpGAkR...|\n",
      "|330457|   Frozen Collection|/13Op41T3cALJedrK...|/s3vdRkK7KZFUDC8H...|\n",
      "|351286|Jurassic Park Col...|/qIm2nHXLpBBdMxi8...|/njFixYzIxX8jsn6K...|\n",
      "|109445|   Frozen Collection|/13Op41T3cALJedrK...|/s3vdRkK7KZFUDC8H...|\n",
      "|321612|                null|                null|                null|\n",
      "|260513|The Incredibles C...|/iOz4Zz72JIqkuTXS...|/6oi6V1O9MJRNnfV8...|\n",
      "+------+--------------------+--------------------+--------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'dcp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 46\u001b[0m\n\u001b[1;32m     35\u001b[0m df_final\u001b[38;5;241m.\u001b[39mshow()\n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m# json_columns = ['belongs_to_collection', 'genres', 'production_countries','production_companies', 'spoken_languages','credits']\u001b[39;00m\n\u001b[1;32m     38\u001b[0m \n\u001b[1;32m     39\u001b[0m \u001b[38;5;66;03m# applies the function to the affected columns\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     43\u001b[0m \n\u001b[1;32m     44\u001b[0m \u001b[38;5;66;03m# df.head()\u001b[39;00m\n\u001b[0;32m---> 46\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mdcp\u001b[49m\u001b[38;5;241m.\u001b[39mconvert_json_columns(df, json_columns)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dcp' is not defined"
     ]
    }
   ],
   "source": [
    "# #Function to convert a string like items to actual python objects which could be list or dictionary \n",
    "# def evaluate_json_column(column):\n",
    "#     try:\n",
    "#         # checks if value is na otherwise converts to object\n",
    "#         return ast.literal_eval(column) if pd.notna(column) else {}\n",
    "#     except (ValueError, SyntaxError):\n",
    "#         return {}\n",
    "\n",
    "\n",
    "from pyspark.sql.functions import from_json\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType\n",
    "\n",
    "# # Sample DataFrame with a JSON column\n",
    "# data = [(\"1\", '{\"name\": \"Alice\", \"age\": 30}'), (\"2\", '{\"name\": \"Bob\", \"age\": 25}')]\n",
    "# df = spark.createDataFrame(data, [\"id\", \"json_string\"])\n",
    "\n",
    "# Define the schema for the JSON data\n",
    "schema = StructType([\n",
    "    StructField(\"id\", IntegerType(), True),\n",
    "    StructField(\"name\", StringType(), True),\n",
    "    StructField(\"poster_path\", StringType(), True),\n",
    "    StructField(\"backdrop_path\", StringType(), True),\n",
    "    \n",
    "    \n",
    "])\n",
    "\n",
    "# (['belongs_to_collection', 'genres', 'production_countries',\n",
    "# 'production_companies', 'spoken_languages'])\n",
    "\n",
    "# Parse the JSON column\n",
    "df_parsed = df.withColumn(\"parsed_json\", from_json(\"belongs_to_collection\", schema))\n",
    "\n",
    "# Select the parsed fields\n",
    "df_final = df_parsed.select(\"id\", \"parsed_json.name\", \"parsed_json.poster_path\",\"parsed_json.backdrop_path\")\n",
    "df_final.show()\n",
    "\n",
    "# json_columns = ['belongs_to_collection', 'genres', 'production_countries','production_companies', 'spoken_languages','credits']\n",
    "\n",
    "# applies the function to the affected columns\n",
    "# for col in json_columns:\n",
    "#     df[col] = df[col].apply(dcp.convert_json_columns)\n",
    "\n",
    "\n",
    "# df.head()\n",
    "\n",
    "# df = dcp.convert_json_columns(df, json_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "backdrop_path: <class 'str'>\n",
      "belongs_to_collection: <class 'dict'>\n",
      "budget: <class 'numpy.int64'>\n",
      "genres: <class 'list'>\n",
      "id: <class 'numpy.int64'>\n",
      "origin_country: <class 'str'>\n",
      "original_language: <class 'str'>\n",
      "overview: <class 'str'>\n",
      "popularity: <class 'numpy.float64'>\n",
      "poster_path: <class 'str'>\n",
      "production_companies: <class 'list'>\n",
      "production_countries: <class 'list'>\n",
      "release_date: <class 'str'>\n",
      "revenue: <class 'numpy.int64'>\n",
      "runtime: <class 'numpy.int64'>\n",
      "spoken_languages: <class 'list'>\n",
      "status: <class 'str'>\n",
      "tagline: <class 'str'>\n",
      "title: <class 'str'>\n",
      "vote_average: <class 'numpy.float64'>\n",
      "vote_count: <class 'numpy.int64'>\n",
      "credits: <class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "#checking if above cell worked \n",
    "for col in df.columns:\n",
    "    print(f\"{col}: {type(df[col].iloc[0])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['backdrop_path', 'belongs_to_collection', 'budget', 'genres', 'id',\n",
       "       'origin_country', 'original_language', 'overview', 'popularity',\n",
       "       'poster_path', 'production_companies', 'production_countries',\n",
       "       'release_date', 'revenue', 'runtime', 'spoken_languages', 'status',\n",
       "       'tagline', 'title', 'vote_average', 'vote_count', 'credits'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract and clean key data points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # function to extract name from the  dictionary in the column \n",
    "# def extract_collection_name(value):\n",
    "#     try:\n",
    "#         if pd.notnull(value) and isinstance(value, dict):\n",
    "#             return value.get('name')\n",
    "#     except (ValueError, SyntaxError):\n",
    "#         return None\n",
    "\n",
    "# Apply function to the column\n",
    "df['collection_name'] = df['belongs_to_collection'].apply(dcp.extract_collection_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The Avengers Collection'"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['collection_name'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 12, 'name': 'Adventure'},\n",
       " {'id': 878, 'name': 'Science Fiction'},\n",
       " {'id': 28, 'name': 'Action'}]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['genres'][0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                      English | 日本語 | \n",
       "1                                     English | Español\n",
       "2                                               English\n",
       "3                                            English | \n",
       "4     English | Français | Deutsch | svenska | Itali...\n",
       "5                                               English\n",
       "6                                               English\n",
       "7                            English | हिन्दी | Pусский\n",
       "8                 العربية | English | Español | ภาษาไทย\n",
       "9                                               English\n",
       "10                     English | 한국어/조선말 | Kiswahili | \n",
       "11                                              English\n",
       "12                                              English\n",
       "13                                              English\n",
       "14                                    English | Pусский\n",
       "15                                              English\n",
       "16                                   English | Français\n",
       "17                                              English\n",
       "Name: original_language, dtype: object"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# #separate the mutliple keys called name in the dictionary with '|'\n",
    "# def break_data_points(df, init_column, new_column):\n",
    "#   df[new_column] = df[init_column].apply(lambda x: ' | '.join(d['name'] for d in x) if isinstance(x, list) else None)\n",
    "#   return df[new_column]\n",
    "      \n",
    "    \n",
    "dcp.break_data_points(df,'genres','genre_names')\n",
    "dcp.break_data_points(df, 'production_countries', 'cld_production_countries')\n",
    "dcp.break_data_points(df, 'production_companies', 'cld_production_companies')\n",
    "dcp.break_data_points(df, 'spoken_languages', 'original_language')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract and add new columns\n",
    "df['cast'] = df['credits'].apply(lambda x: ' | '.join(dcp.extract_cast_names(x)))\n",
    "df['crew'] = df['credits'].apply(lambda x: ' | '.join(dcp.extract_crew_names(x)))\n",
    "df['director'] = df['credits'].apply(dcp.extract_director)\n",
    "df['cast_size'] = df['credits'].apply(lambda x: len(x.get('cast', [])))\n",
    "df['crew_size'] = df['credits'].apply(lambda x: len(x.get('crew', [])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    593\n",
       "1    986\n",
       "2    257\n",
       "3    724\n",
       "4    258\n",
       "Name: crew_size, dtype: int64"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['cast'].head()\n",
    "df['crew'].head()\n",
    "df['director'].head()\n",
    "df['cast_size'].head()\n",
    "df['crew_size'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['backdrop_path', 'belongs_to_collection', 'budget', 'genres', 'id',\n",
       "       'origin_country', 'original_language', 'overview', 'popularity',\n",
       "       'poster_path', 'production_companies', 'production_countries',\n",
       "       'release_date', 'revenue', 'runtime', 'spoken_languages', 'status',\n",
       "       'tagline', 'title', 'vote_average', 'vote_count', 'credits',\n",
       "       'collection_name', 'genre_names', 'cld_production_countries',\n",
       "       'cld_production_companies', 'cast', 'crew', 'director', 'cast_size',\n",
       "       'crew_size'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identify Anomalies with value_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # function to pick the value_counts of each specified column\n",
    "# def get_value_counts(df, column):\n",
    "#     return df[column].value_counts()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "genre_names\n",
       "Adventure | Action | Science Fiction                 3\n",
       "Action | Adventure | Science Fiction | Thriller      2\n",
       "Action | Adventure | Science Fiction                 2\n",
       "Adventure | Science Fiction | Action                 1\n",
       "Action | Adventure | Fantasy | Science Fiction       1\n",
       "Drama | Romance                                      1\n",
       "Adventure | Drama | Family | Animation               1\n",
       "Science Fiction | Action | Adventure                 1\n",
       "Action | Thriller | Crime                            1\n",
       "Fantasy | Adventure                                  1\n",
       "Family | Animation | Adventure | Comedy | Fantasy    1\n",
       "Animation | Family | Adventure | Fantasy             1\n",
       "Family | Fantasy | Romance                           1\n",
       "Action | Adventure | Animation | Family              1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dcp.get_value_counts(df, 'genre_names')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cld_production_countries\n",
       "United States of America                     16\n",
       "United States of America | United Kingdom     1\n",
       "United Kingdom | United States of America     1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dcp.get_value_counts(df, 'cld_production_countries')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "original_language\n",
       "English                                                        9\n",
       "English | 日本語 |                                                1\n",
       "English | Español                                              1\n",
       "English |                                                      1\n",
       "English | Français | Deutsch | svenska | Italiano | Pусский    1\n",
       "English | हिन्दी | Pусский                                     1\n",
       "العربية | English | Español | ภาษาไทย                          1\n",
       "English | 한국어/조선말 | Kiswahili |                                1\n",
       "English | Pусский                                              1\n",
       "English | Français                                             1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dcp.get_value_counts(df, 'original_language')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # \n",
    "# def normalize_anomalies(genre_string):\n",
    "#     # converts the split genres names to a list and sorts them and returns them to have them be unique\n",
    "#     genres = list(genrestring.strip() for genrestring in genre_string.split('|'))\n",
    "#     sorted_genres = sorted(genres)\n",
    "#     return ' | '.join(sorted_genres)\n",
    "\n",
    "df['genre_names']= df['genre_names'].apply(dcp.normalize_anomalies)\n",
    "df['cld_production_countries']= df['cld_production_countries'].apply(dcp.normalize_anomalies)\n",
    "df['cld_production_companies']= df['cld_production_companies'].apply(dcp.normalize_anomalies)\n",
    "df['original_language']= df['original_language'].apply(dcp.normalize_anomalies)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### testing anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "genre_names\n",
       "Action | Adventure | Science Fiction                 7\n",
       "Action | Adventure | Science Fiction | Thriller      2\n",
       "Action | Adventure | Fantasy | Science Fiction       1\n",
       "Drama | Romance                                      1\n",
       "Adventure | Animation | Drama | Family               1\n",
       "Action | Crime | Thriller                            1\n",
       "Adventure | Fantasy                                  1\n",
       "Adventure | Animation | Comedy | Family | Fantasy    1\n",
       "Adventure | Animation | Family | Fantasy             1\n",
       "Family | Fantasy | Romance                           1\n",
       "Action | Adventure | Animation | Family              1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['genre_names'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cld_production_countries\n",
       "United States of America                     16\n",
       "United Kingdom | United States of America     2\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['cld_production_countries'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cld_production_companies\n",
       "Marvel Studios                                                                        5\n",
       "Amblin Entertainment | Universal Pictures                                             2\n",
       "Walt Disney Animation Studios | Walt Disney Pictures                                  2\n",
       "20th Century Fox | Dune Entertainment | Ingenious Media | Lightstorm Entertainment    1\n",
       "Bad Robot | Lucasfilm Ltd.                                                            1\n",
       "20th Century Fox | Lightstorm Entertainment | Paramount Pictures                      1\n",
       "Fairview Entertainment | Walt Disney Pictures                                         1\n",
       "One Race | Original Film | Universal Pictures                                         1\n",
       "Heyday Films | Warner Bros. Pictures                                                  1\n",
       "Lucasfilm Ltd.                                                                        1\n",
       "Mandeville Films | Walt Disney Pictures                                               1\n",
       "Pixar | Walt Disney Pictures                                                          1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['cld_production_companies'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "original_language\n",
       "English                                                        9\n",
       " | English | 日本語                                               1\n",
       "English | Español                                              1\n",
       " | English                                                     1\n",
       "Deutsch | English | Français | Italiano | Pусский | svenska    1\n",
       "English | Pусский | हिन्दी                                     1\n",
       "English | Español | العربية | ภาษาไทย                          1\n",
       " | English | Kiswahili | 한국어/조선말                               1\n",
       "English | Pусский                                              1\n",
       "English | Français                                             1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['original_language'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling Missing & Incorrect Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "RangeIndex: 18 entries, 0 to 17\n",
      "Series name: id\n",
      "Non-Null Count  Dtype\n",
      "--------------  -----\n",
      "18 non-null     int64\n",
      "dtypes: int64(1)\n",
      "memory usage: 272.0 bytes\n",
      "<class 'pandas.core.series.Series'>\n",
      "RangeIndex: 18 entries, 0 to 17\n",
      "Series name: popularity\n",
      "Non-Null Count  Dtype  \n",
      "--------------  -----  \n",
      "18 non-null     float64\n",
      "dtypes: float64(1)\n",
      "memory usage: 272.0 bytes\n",
      "<class 'pandas.core.series.Series'>\n",
      "RangeIndex: 18 entries, 0 to 17\n",
      "Series name: budget\n",
      "Non-Null Count  Dtype\n",
      "--------------  -----\n",
      "18 non-null     int64\n",
      "dtypes: int64(1)\n",
      "memory usage: 272.0 bytes\n"
     ]
    }
   ],
   "source": [
    "dcp.convert_to_numeric(df, 'id')\n",
    "dcp.convert_to_numeric(df, 'popularity')\n",
    "dcp.convert_to_numeric(df,'budget')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_datetime(df,column):\n",
    "         df[column] = pd.to_datetime(df[column])\n",
    "         return df[column].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "RangeIndex: 18 entries, 0 to 17\n",
      "Series name: release_date\n",
      "Non-Null Count  Dtype         \n",
      "--------------  -----         \n",
      "18 non-null     datetime64[ns]\n",
      "dtypes: datetime64[ns](1)\n",
      "memory usage: 272.0 bytes\n"
     ]
    }
   ],
   "source": [
    "dcp.convert_to_datetime(df,'release_date')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replace unrealistic values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No zero values found in column 'budget'.\n",
      "No zero values found in column 'revenue'.\n",
      "No zero values found in column 'runtime'.\n"
     ]
    }
   ],
   "source": [
    "dcp.check_zero_in_column(df, 'budget')\n",
    "dcp.check_zero_in_column(df, 'revenue')\n",
    "dcp.check_zero_in_column(df, 'runtime')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Convert Budget and Revenue to Million USD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2799.44\n",
       "1    2923.71\n",
       "2    2068.22\n",
       "3    2052.42\n",
       "4    2264.16\n",
       "Name: revenue_musd, dtype: float64"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['budget_musd'] = df['budget'] / 1_000_000\n",
    "df['revenue_musd'] = df['revenue']/ 1_000_000\n",
    "df['revenue_musd'] = df['revenue_musd'].round(2)\n",
    "df.drop(columns= ['budget','revenue'], inplace= True)\n",
    "\n",
    "df['budget_musd'].head()\n",
    "df['revenue_musd'].head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26214"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['vote_count'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['backdrop_path', 'belongs_to_collection', 'genres', 'id',\n",
       "       'origin_country', 'original_language', 'overview', 'popularity',\n",
       "       'poster_path', 'production_companies', 'production_countries',\n",
       "       'release_date', 'runtime', 'spoken_languages', 'status', 'tagline',\n",
       "       'title', 'vote_average', 'vote_count', 'credits', 'collection_name',\n",
       "       'genre_names', 'cld_production_countries', 'cld_production_companies',\n",
       "       'cast', 'crew', 'director', 'cast_size', 'crew_size', 'budget_musd',\n",
       "       'revenue_musd'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>backdrop_path</th>\n",
       "      <th>belongs_to_collection</th>\n",
       "      <th>genres</th>\n",
       "      <th>id</th>\n",
       "      <th>origin_country</th>\n",
       "      <th>original_language</th>\n",
       "      <th>overview</th>\n",
       "      <th>popularity</th>\n",
       "      <th>poster_path</th>\n",
       "      <th>production_companies</th>\n",
       "      <th>...</th>\n",
       "      <th>genre_names</th>\n",
       "      <th>cld_production_countries</th>\n",
       "      <th>cld_production_companies</th>\n",
       "      <th>cast</th>\n",
       "      <th>crew</th>\n",
       "      <th>director</th>\n",
       "      <th>cast_size</th>\n",
       "      <th>crew_size</th>\n",
       "      <th>budget_musd</th>\n",
       "      <th>revenue_musd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [backdrop_path, belongs_to_collection, genres, id, origin_country, original_language, overview, popularity, poster_path, production_companies, production_countries, release_date, runtime, spoken_languages, status, tagline, title, vote_average, vote_count, credits, collection_name, genre_names, cld_production_countries, cld_production_companies, cast, crew, director, cast_size, crew_size, budget_musd, revenue_musd]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 31 columns]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dcp.vote_count_zero(df, 'vote_count')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tagline'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                    Avenge the fallen.\n",
       "1                           Enter the world of Pandora.\n",
       "2                         Every generation has a story.\n",
       "3                         Destiny arrives all the same.\n",
       "4             Nothing on Earth could come between them.\n",
       "5                                     The park is open.\n",
       "6                                The king has returned.\n",
       "7                               Some assembly required.\n",
       "8                                  Vengeance hits home.\n",
       "9                                   A new age has come.\n",
       "10                                  Long live the king.\n",
       "11                                         It all ends.\n",
       "12               Darkness rises...and light to meet it.\n",
       "13                       The past is not what it seems.\n",
       "14                                    The park is gone.\n",
       "15    Only the act of true love will thaw a frozen h...\n",
       "16                                        Be our guest.\n",
       "17                        It's been too long, dahlings.\n",
       "Name: tagline, dtype: object"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tagline']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['overview'].nunique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>backdrop_path</th>\n",
       "      <th>belongs_to_collection</th>\n",
       "      <th>genres</th>\n",
       "      <th>id</th>\n",
       "      <th>origin_country</th>\n",
       "      <th>original_language</th>\n",
       "      <th>overview</th>\n",
       "      <th>popularity</th>\n",
       "      <th>poster_path</th>\n",
       "      <th>production_companies</th>\n",
       "      <th>...</th>\n",
       "      <th>genre_names</th>\n",
       "      <th>cld_production_countries</th>\n",
       "      <th>cld_production_companies</th>\n",
       "      <th>cast</th>\n",
       "      <th>crew</th>\n",
       "      <th>director</th>\n",
       "      <th>cast_size</th>\n",
       "      <th>crew_size</th>\n",
       "      <th>budget_musd</th>\n",
       "      <th>revenue_musd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [backdrop_path, belongs_to_collection, genres, id, origin_country, original_language, overview, popularity, poster_path, production_companies, production_countries, release_date, runtime, spoken_languages, status, tagline, title, vote_average, vote_count, credits, collection_name, genre_names, cld_production_countries, cld_production_companies, cast, crew, director, cast_size, crew_size, budget_musd, revenue_musd]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 31 columns]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dcp.check_for_nodata(df, 'overview')\n",
    "dcp.check_for_nodata(df, 'tagline')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     False\n",
       "1     False\n",
       "2     False\n",
       "3     False\n",
       "4     False\n",
       "5     False\n",
       "6     False\n",
       "7     False\n",
       "8     False\n",
       "9     False\n",
       "10    False\n",
       "11    False\n",
       "12    False\n",
       "13    False\n",
       "14    False\n",
       "15    False\n",
       "16    False\n",
       "17    False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#converts all dictionaries and lists to strings to check for duplicate\n",
    "df_str = df.applymap(lambda x: str(x) if isinstance(x, (dict, list)) else x)\n",
    "duplicates = df_str.duplicated()\n",
    "duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['backdrop_path', 'belongs_to_collection', 'genres', 'id',\n",
       "       'origin_country', 'original_language', 'overview', 'popularity',\n",
       "       'poster_path', 'production_companies', 'production_countries',\n",
       "       'release_date', 'runtime', 'spoken_languages', 'status', 'tagline',\n",
       "       'title', 'vote_average', 'vote_count', 'credits', 'collection_name',\n",
       "       'genre_names', 'cld_production_countries', 'cld_production_companies',\n",
       "       'cast', 'crew', 'director', 'cast_size', 'crew_size', 'budget_musd',\n",
       "       'revenue_musd'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>backdrop_path</th>\n",
       "      <th>belongs_to_collection</th>\n",
       "      <th>genres</th>\n",
       "      <th>id</th>\n",
       "      <th>origin_country</th>\n",
       "      <th>original_language</th>\n",
       "      <th>overview</th>\n",
       "      <th>popularity</th>\n",
       "      <th>poster_path</th>\n",
       "      <th>production_companies</th>\n",
       "      <th>...</th>\n",
       "      <th>genre_names</th>\n",
       "      <th>cld_production_countries</th>\n",
       "      <th>cld_production_companies</th>\n",
       "      <th>cast</th>\n",
       "      <th>crew</th>\n",
       "      <th>director</th>\n",
       "      <th>cast_size</th>\n",
       "      <th>crew_size</th>\n",
       "      <th>budget_musd</th>\n",
       "      <th>revenue_musd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/7RyHsO4yDXtBv1zUU3mTpHeQ0d5.jpg</td>\n",
       "      <td>{'id': 86311, 'name': 'The Avengers Collection...</td>\n",
       "      <td>[{'id': 12, 'name': 'Adventure'}, {'id': 878, ...</td>\n",
       "      <td>299534</td>\n",
       "      <td>['US']</td>\n",
       "      <td>| English | 日本語</td>\n",
       "      <td>After the devastating events of Avengers: Infi...</td>\n",
       "      <td>24.2346</td>\n",
       "      <td>/ulzhLuWrPK07P1YkdWQLZnQh1JL.jpg</td>\n",
       "      <td>[{'id': 420, 'logo_path': '/hUzeosd33nzE5MCNsZ...</td>\n",
       "      <td>...</td>\n",
       "      <td>Action | Adventure | Science Fiction</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>Marvel Studios</td>\n",
       "      <td>Robert Downey Jr. | Chris Evans | Mark Ruffalo...</td>\n",
       "      <td>Paul Schneider | Louis D'Esposito | Carlos Pac...</td>\n",
       "      <td>Anthony Russo</td>\n",
       "      <td>105</td>\n",
       "      <td>593</td>\n",
       "      <td>356.0</td>\n",
       "      <td>2799.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/vL5LR6WdxWPjLPFRLe133jXWsh5.jpg</td>\n",
       "      <td>{'id': 87096, 'name': 'Avatar Collection', 'po...</td>\n",
       "      <td>[{'id': 28, 'name': 'Action'}, {'id': 12, 'nam...</td>\n",
       "      <td>19995</td>\n",
       "      <td>['US']</td>\n",
       "      <td>English | Español</td>\n",
       "      <td>In the 22nd century, a paraplegic Marine is di...</td>\n",
       "      <td>32.6950</td>\n",
       "      <td>/kyeqWdyUXW608qlYkRqosgbbJyK.jpg</td>\n",
       "      <td>[{'id': 444, 'logo_path': None, 'name': 'Dune ...</td>\n",
       "      <td>...</td>\n",
       "      <td>Action | Adventure | Fantasy | Science Fiction</td>\n",
       "      <td>United Kingdom | United States of America</td>\n",
       "      <td>20th Century Fox | Dune Entertainment | Ingeni...</td>\n",
       "      <td>Sam Worthington | Zoe Saldaña | Sigourney Weav...</td>\n",
       "      <td>James Cameron | James Cameron | Ilram Choi | W...</td>\n",
       "      <td>James Cameron</td>\n",
       "      <td>65</td>\n",
       "      <td>986</td>\n",
       "      <td>237.0</td>\n",
       "      <td>2923.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/k6EOrckWFuz7I4z4wiRwz8zsj4H.jpg</td>\n",
       "      <td>{'id': 10, 'name': 'Star Wars Collection', 'po...</td>\n",
       "      <td>[{'id': 12, 'name': 'Adventure'}, {'id': 28, '...</td>\n",
       "      <td>140607</td>\n",
       "      <td>['US']</td>\n",
       "      <td>English</td>\n",
       "      <td>Thirty years after defeating the Galactic Empi...</td>\n",
       "      <td>13.1664</td>\n",
       "      <td>/wqnLdwVXoBjKibFRR5U3y0aDUhs.jpg</td>\n",
       "      <td>[{'id': 1, 'logo_path': '/tlVSws0RvvtPBwViUyOF...</td>\n",
       "      <td>...</td>\n",
       "      <td>Action | Adventure | Science Fiction</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>Bad Robot | Lucasfilm Ltd.</td>\n",
       "      <td>Harrison Ford | Mark Hamill | Carrie Fisher | ...</td>\n",
       "      <td>Ron Jones | J.J. Abrams | Bryan Burk | J.J. Ab...</td>\n",
       "      <td>J.J. Abrams</td>\n",
       "      <td>182</td>\n",
       "      <td>257</td>\n",
       "      <td>245.0</td>\n",
       "      <td>2068.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/mDfJG3LC3Dqb67AZ52x3Z0jU0uB.jpg</td>\n",
       "      <td>{'id': 86311, 'name': 'The Avengers Collection...</td>\n",
       "      <td>[{'id': 12, 'name': 'Adventure'}, {'id': 28, '...</td>\n",
       "      <td>299536</td>\n",
       "      <td>['US']</td>\n",
       "      <td>| English</td>\n",
       "      <td>As the Avengers and their allies have continue...</td>\n",
       "      <td>33.0700</td>\n",
       "      <td>/7WsyChQLEftFiDOVTGkv3hFpyyt.jpg</td>\n",
       "      <td>[{'id': 420, 'logo_path': '/hUzeosd33nzE5MCNsZ...</td>\n",
       "      <td>...</td>\n",
       "      <td>Action | Adventure | Science Fiction</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>Marvel Studios</td>\n",
       "      <td>Robert Downey Jr. | Chris Evans | Chris Hemswo...</td>\n",
       "      <td>Paul Schneider | John David Duncan | Jwaundace...</td>\n",
       "      <td>Joe Russo</td>\n",
       "      <td>69</td>\n",
       "      <td>724</td>\n",
       "      <td>300.0</td>\n",
       "      <td>2052.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/sCzcYW9h55WcesOqA12cgEr9Exw.jpg</td>\n",
       "      <td>{}</td>\n",
       "      <td>[{'id': 18, 'name': 'Drama'}, {'id': 10749, 'n...</td>\n",
       "      <td>597</td>\n",
       "      <td>['US']</td>\n",
       "      <td>Deutsch | English | Français | Italiano | Pусс...</td>\n",
       "      <td>101-year-old Rose DeWitt Bukater tells the sto...</td>\n",
       "      <td>38.6063</td>\n",
       "      <td>/9xjZS2rlVxm8SFx8kPC3aIGCOYQ.jpg</td>\n",
       "      <td>[{'id': 4, 'logo_path': '/gz66EfNoYPqHTYI4q9UE...</td>\n",
       "      <td>...</td>\n",
       "      <td>Drama | Romance</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>20th Century Fox | Lightstorm Entertainment | ...</td>\n",
       "      <td>Leonardo DiCaprio | Kate Winslet | Billy Zane ...</td>\n",
       "      <td>James Cameron | Sharon Mann | Emily Schweber |...</td>\n",
       "      <td>James Cameron</td>\n",
       "      <td>116</td>\n",
       "      <td>258</td>\n",
       "      <td>200.0</td>\n",
       "      <td>2264.16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      backdrop_path  \\\n",
       "0  /7RyHsO4yDXtBv1zUU3mTpHeQ0d5.jpg   \n",
       "1  /vL5LR6WdxWPjLPFRLe133jXWsh5.jpg   \n",
       "2  /k6EOrckWFuz7I4z4wiRwz8zsj4H.jpg   \n",
       "3  /mDfJG3LC3Dqb67AZ52x3Z0jU0uB.jpg   \n",
       "4  /sCzcYW9h55WcesOqA12cgEr9Exw.jpg   \n",
       "\n",
       "                               belongs_to_collection  \\\n",
       "0  {'id': 86311, 'name': 'The Avengers Collection...   \n",
       "1  {'id': 87096, 'name': 'Avatar Collection', 'po...   \n",
       "2  {'id': 10, 'name': 'Star Wars Collection', 'po...   \n",
       "3  {'id': 86311, 'name': 'The Avengers Collection...   \n",
       "4                                                 {}   \n",
       "\n",
       "                                              genres      id origin_country  \\\n",
       "0  [{'id': 12, 'name': 'Adventure'}, {'id': 878, ...  299534         ['US']   \n",
       "1  [{'id': 28, 'name': 'Action'}, {'id': 12, 'nam...   19995         ['US']   \n",
       "2  [{'id': 12, 'name': 'Adventure'}, {'id': 28, '...  140607         ['US']   \n",
       "3  [{'id': 12, 'name': 'Adventure'}, {'id': 28, '...  299536         ['US']   \n",
       "4  [{'id': 18, 'name': 'Drama'}, {'id': 10749, 'n...     597         ['US']   \n",
       "\n",
       "                                   original_language  \\\n",
       "0                                    | English | 日本語   \n",
       "1                                  English | Español   \n",
       "2                                            English   \n",
       "3                                          | English   \n",
       "4  Deutsch | English | Français | Italiano | Pусс...   \n",
       "\n",
       "                                            overview  popularity  \\\n",
       "0  After the devastating events of Avengers: Infi...     24.2346   \n",
       "1  In the 22nd century, a paraplegic Marine is di...     32.6950   \n",
       "2  Thirty years after defeating the Galactic Empi...     13.1664   \n",
       "3  As the Avengers and their allies have continue...     33.0700   \n",
       "4  101-year-old Rose DeWitt Bukater tells the sto...     38.6063   \n",
       "\n",
       "                        poster_path  \\\n",
       "0  /ulzhLuWrPK07P1YkdWQLZnQh1JL.jpg   \n",
       "1  /kyeqWdyUXW608qlYkRqosgbbJyK.jpg   \n",
       "2  /wqnLdwVXoBjKibFRR5U3y0aDUhs.jpg   \n",
       "3  /7WsyChQLEftFiDOVTGkv3hFpyyt.jpg   \n",
       "4  /9xjZS2rlVxm8SFx8kPC3aIGCOYQ.jpg   \n",
       "\n",
       "                                production_companies  ...  \\\n",
       "0  [{'id': 420, 'logo_path': '/hUzeosd33nzE5MCNsZ...  ...   \n",
       "1  [{'id': 444, 'logo_path': None, 'name': 'Dune ...  ...   \n",
       "2  [{'id': 1, 'logo_path': '/tlVSws0RvvtPBwViUyOF...  ...   \n",
       "3  [{'id': 420, 'logo_path': '/hUzeosd33nzE5MCNsZ...  ...   \n",
       "4  [{'id': 4, 'logo_path': '/gz66EfNoYPqHTYI4q9UE...  ...   \n",
       "\n",
       "                                      genre_names  \\\n",
       "0            Action | Adventure | Science Fiction   \n",
       "1  Action | Adventure | Fantasy | Science Fiction   \n",
       "2            Action | Adventure | Science Fiction   \n",
       "3            Action | Adventure | Science Fiction   \n",
       "4                                 Drama | Romance   \n",
       "\n",
       "                    cld_production_countries  \\\n",
       "0                   United States of America   \n",
       "1  United Kingdom | United States of America   \n",
       "2                   United States of America   \n",
       "3                   United States of America   \n",
       "4                   United States of America   \n",
       "\n",
       "                            cld_production_companies  \\\n",
       "0                                     Marvel Studios   \n",
       "1  20th Century Fox | Dune Entertainment | Ingeni...   \n",
       "2                         Bad Robot | Lucasfilm Ltd.   \n",
       "3                                     Marvel Studios   \n",
       "4  20th Century Fox | Lightstorm Entertainment | ...   \n",
       "\n",
       "                                                cast  \\\n",
       "0  Robert Downey Jr. | Chris Evans | Mark Ruffalo...   \n",
       "1  Sam Worthington | Zoe Saldaña | Sigourney Weav...   \n",
       "2  Harrison Ford | Mark Hamill | Carrie Fisher | ...   \n",
       "3  Robert Downey Jr. | Chris Evans | Chris Hemswo...   \n",
       "4  Leonardo DiCaprio | Kate Winslet | Billy Zane ...   \n",
       "\n",
       "                                                crew       director  \\\n",
       "0  Paul Schneider | Louis D'Esposito | Carlos Pac...  Anthony Russo   \n",
       "1  James Cameron | James Cameron | Ilram Choi | W...  James Cameron   \n",
       "2  Ron Jones | J.J. Abrams | Bryan Burk | J.J. Ab...    J.J. Abrams   \n",
       "3  Paul Schneider | John David Duncan | Jwaundace...      Joe Russo   \n",
       "4  James Cameron | Sharon Mann | Emily Schweber |...  James Cameron   \n",
       "\n",
       "   cast_size  crew_size budget_musd revenue_musd  \n",
       "0        105        593       356.0      2799.44  \n",
       "1         65        986       237.0      2923.71  \n",
       "2        182        257       245.0      2068.22  \n",
       "3         69        724       300.0      2052.42  \n",
       "4        116        258       200.0      2264.16  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dcp.released_movies(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['backdrop_path', 'belongs_to_collection', 'genres', 'id',\n",
       "       'origin_country', 'original_language', 'overview', 'popularity',\n",
       "       'poster_path', 'production_companies', 'production_countries',\n",
       "       'release_date', 'runtime', 'spoken_languages', 'status', 'tagline',\n",
       "       'title', 'vote_average', 'vote_count', 'credits', 'collection_name',\n",
       "       'genre_names', 'cld_production_countries', 'cld_production_companies',\n",
       "       'cast', 'crew', 'director', 'cast_size', 'crew_size', 'budget_musd',\n",
       "       'revenue_musd'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>tagline</th>\n",
       "      <th>release_date</th>\n",
       "      <th>genres</th>\n",
       "      <th>belongs_to_collection</th>\n",
       "      <th>original_language</th>\n",
       "      <th>budget_musd</th>\n",
       "      <th>revenue_musd</th>\n",
       "      <th>production_companies</th>\n",
       "      <th>...</th>\n",
       "      <th>crew_size</th>\n",
       "      <th>backdrop_path</th>\n",
       "      <th>origin_country</th>\n",
       "      <th>status</th>\n",
       "      <th>credits</th>\n",
       "      <th>collection_name</th>\n",
       "      <th>genre_names</th>\n",
       "      <th>cld_production_countries</th>\n",
       "      <th>cld_production_companies</th>\n",
       "      <th>crew</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>299534</td>\n",
       "      <td>Avengers: Endgame</td>\n",
       "      <td>Avenge the fallen.</td>\n",
       "      <td>2019-04-24</td>\n",
       "      <td>[{'id': 12, 'name': 'Adventure'}, {'id': 878, ...</td>\n",
       "      <td>{'id': 86311, 'name': 'The Avengers Collection...</td>\n",
       "      <td>| English | 日本語</td>\n",
       "      <td>356.0</td>\n",
       "      <td>2799.44</td>\n",
       "      <td>[{'id': 420, 'logo_path': '/hUzeosd33nzE5MCNsZ...</td>\n",
       "      <td>...</td>\n",
       "      <td>593</td>\n",
       "      <td>/7RyHsO4yDXtBv1zUU3mTpHeQ0d5.jpg</td>\n",
       "      <td>['US']</td>\n",
       "      <td>Released</td>\n",
       "      <td>{'cast': [{'adult': False, 'gender': 2, 'id': ...</td>\n",
       "      <td>The Avengers Collection</td>\n",
       "      <td>Action | Adventure | Science Fiction</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>Marvel Studios</td>\n",
       "      <td>Paul Schneider | Louis D'Esposito | Carlos Pac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19995</td>\n",
       "      <td>Avatar</td>\n",
       "      <td>Enter the world of Pandora.</td>\n",
       "      <td>2009-12-15</td>\n",
       "      <td>[{'id': 28, 'name': 'Action'}, {'id': 12, 'nam...</td>\n",
       "      <td>{'id': 87096, 'name': 'Avatar Collection', 'po...</td>\n",
       "      <td>English | Español</td>\n",
       "      <td>237.0</td>\n",
       "      <td>2923.71</td>\n",
       "      <td>[{'id': 444, 'logo_path': None, 'name': 'Dune ...</td>\n",
       "      <td>...</td>\n",
       "      <td>986</td>\n",
       "      <td>/vL5LR6WdxWPjLPFRLe133jXWsh5.jpg</td>\n",
       "      <td>['US']</td>\n",
       "      <td>Released</td>\n",
       "      <td>{'cast': [{'adult': False, 'gender': 2, 'id': ...</td>\n",
       "      <td>Avatar Collection</td>\n",
       "      <td>Action | Adventure | Fantasy | Science Fiction</td>\n",
       "      <td>United Kingdom | United States of America</td>\n",
       "      <td>20th Century Fox | Dune Entertainment | Ingeni...</td>\n",
       "      <td>James Cameron | James Cameron | Ilram Choi | W...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>140607</td>\n",
       "      <td>Star Wars: The Force Awakens</td>\n",
       "      <td>Every generation has a story.</td>\n",
       "      <td>2015-12-15</td>\n",
       "      <td>[{'id': 12, 'name': 'Adventure'}, {'id': 28, '...</td>\n",
       "      <td>{'id': 10, 'name': 'Star Wars Collection', 'po...</td>\n",
       "      <td>English</td>\n",
       "      <td>245.0</td>\n",
       "      <td>2068.22</td>\n",
       "      <td>[{'id': 1, 'logo_path': '/tlVSws0RvvtPBwViUyOF...</td>\n",
       "      <td>...</td>\n",
       "      <td>257</td>\n",
       "      <td>/k6EOrckWFuz7I4z4wiRwz8zsj4H.jpg</td>\n",
       "      <td>['US']</td>\n",
       "      <td>Released</td>\n",
       "      <td>{'cast': [{'adult': False, 'gender': 2, 'id': ...</td>\n",
       "      <td>Star Wars Collection</td>\n",
       "      <td>Action | Adventure | Science Fiction</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>Bad Robot | Lucasfilm Ltd.</td>\n",
       "      <td>Ron Jones | J.J. Abrams | Bryan Burk | J.J. Ab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>299536</td>\n",
       "      <td>Avengers: Infinity War</td>\n",
       "      <td>Destiny arrives all the same.</td>\n",
       "      <td>2018-04-25</td>\n",
       "      <td>[{'id': 12, 'name': 'Adventure'}, {'id': 28, '...</td>\n",
       "      <td>{'id': 86311, 'name': 'The Avengers Collection...</td>\n",
       "      <td>| English</td>\n",
       "      <td>300.0</td>\n",
       "      <td>2052.42</td>\n",
       "      <td>[{'id': 420, 'logo_path': '/hUzeosd33nzE5MCNsZ...</td>\n",
       "      <td>...</td>\n",
       "      <td>724</td>\n",
       "      <td>/mDfJG3LC3Dqb67AZ52x3Z0jU0uB.jpg</td>\n",
       "      <td>['US']</td>\n",
       "      <td>Released</td>\n",
       "      <td>{'cast': [{'adult': False, 'gender': 2, 'id': ...</td>\n",
       "      <td>The Avengers Collection</td>\n",
       "      <td>Action | Adventure | Science Fiction</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>Marvel Studios</td>\n",
       "      <td>Paul Schneider | John David Duncan | Jwaundace...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>597</td>\n",
       "      <td>Titanic</td>\n",
       "      <td>Nothing on Earth could come between them.</td>\n",
       "      <td>1997-11-18</td>\n",
       "      <td>[{'id': 18, 'name': 'Drama'}, {'id': 10749, 'n...</td>\n",
       "      <td>{}</td>\n",
       "      <td>Deutsch | English | Français | Italiano | Pусс...</td>\n",
       "      <td>200.0</td>\n",
       "      <td>2264.16</td>\n",
       "      <td>[{'id': 4, 'logo_path': '/gz66EfNoYPqHTYI4q9UE...</td>\n",
       "      <td>...</td>\n",
       "      <td>258</td>\n",
       "      <td>/sCzcYW9h55WcesOqA12cgEr9Exw.jpg</td>\n",
       "      <td>['US']</td>\n",
       "      <td>Released</td>\n",
       "      <td>{'cast': [{'adult': False, 'gender': 2, 'id': ...</td>\n",
       "      <td>None</td>\n",
       "      <td>Drama | Romance</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>20th Century Fox | Lightstorm Entertainment | ...</td>\n",
       "      <td>James Cameron | Sharon Mann | Emily Schweber |...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       id                         title  \\\n",
       "0  299534             Avengers: Endgame   \n",
       "1   19995                        Avatar   \n",
       "2  140607  Star Wars: The Force Awakens   \n",
       "3  299536        Avengers: Infinity War   \n",
       "4     597                       Titanic   \n",
       "\n",
       "                                     tagline release_date  \\\n",
       "0                         Avenge the fallen.   2019-04-24   \n",
       "1                Enter the world of Pandora.   2009-12-15   \n",
       "2              Every generation has a story.   2015-12-15   \n",
       "3              Destiny arrives all the same.   2018-04-25   \n",
       "4  Nothing on Earth could come between them.   1997-11-18   \n",
       "\n",
       "                                              genres  \\\n",
       "0  [{'id': 12, 'name': 'Adventure'}, {'id': 878, ...   \n",
       "1  [{'id': 28, 'name': 'Action'}, {'id': 12, 'nam...   \n",
       "2  [{'id': 12, 'name': 'Adventure'}, {'id': 28, '...   \n",
       "3  [{'id': 12, 'name': 'Adventure'}, {'id': 28, '...   \n",
       "4  [{'id': 18, 'name': 'Drama'}, {'id': 10749, 'n...   \n",
       "\n",
       "                               belongs_to_collection  \\\n",
       "0  {'id': 86311, 'name': 'The Avengers Collection...   \n",
       "1  {'id': 87096, 'name': 'Avatar Collection', 'po...   \n",
       "2  {'id': 10, 'name': 'Star Wars Collection', 'po...   \n",
       "3  {'id': 86311, 'name': 'The Avengers Collection...   \n",
       "4                                                 {}   \n",
       "\n",
       "                                   original_language  budget_musd  \\\n",
       "0                                    | English | 日本語        356.0   \n",
       "1                                  English | Español        237.0   \n",
       "2                                            English        245.0   \n",
       "3                                          | English        300.0   \n",
       "4  Deutsch | English | Français | Italiano | Pусс...        200.0   \n",
       "\n",
       "   revenue_musd                               production_companies  ...  \\\n",
       "0       2799.44  [{'id': 420, 'logo_path': '/hUzeosd33nzE5MCNsZ...  ...   \n",
       "1       2923.71  [{'id': 444, 'logo_path': None, 'name': 'Dune ...  ...   \n",
       "2       2068.22  [{'id': 1, 'logo_path': '/tlVSws0RvvtPBwViUyOF...  ...   \n",
       "3       2052.42  [{'id': 420, 'logo_path': '/hUzeosd33nzE5MCNsZ...  ...   \n",
       "4       2264.16  [{'id': 4, 'logo_path': '/gz66EfNoYPqHTYI4q9UE...  ...   \n",
       "\n",
       "  crew_size                     backdrop_path  origin_country    status  \\\n",
       "0       593  /7RyHsO4yDXtBv1zUU3mTpHeQ0d5.jpg          ['US']  Released   \n",
       "1       986  /vL5LR6WdxWPjLPFRLe133jXWsh5.jpg          ['US']  Released   \n",
       "2       257  /k6EOrckWFuz7I4z4wiRwz8zsj4H.jpg          ['US']  Released   \n",
       "3       724  /mDfJG3LC3Dqb67AZ52x3Z0jU0uB.jpg          ['US']  Released   \n",
       "4       258  /sCzcYW9h55WcesOqA12cgEr9Exw.jpg          ['US']  Released   \n",
       "\n",
       "                                             credits          collection_name  \\\n",
       "0  {'cast': [{'adult': False, 'gender': 2, 'id': ...  The Avengers Collection   \n",
       "1  {'cast': [{'adult': False, 'gender': 2, 'id': ...        Avatar Collection   \n",
       "2  {'cast': [{'adult': False, 'gender': 2, 'id': ...     Star Wars Collection   \n",
       "3  {'cast': [{'adult': False, 'gender': 2, 'id': ...  The Avengers Collection   \n",
       "4  {'cast': [{'adult': False, 'gender': 2, 'id': ...                     None   \n",
       "\n",
       "                                      genre_names  \\\n",
       "0            Action | Adventure | Science Fiction   \n",
       "1  Action | Adventure | Fantasy | Science Fiction   \n",
       "2            Action | Adventure | Science Fiction   \n",
       "3            Action | Adventure | Science Fiction   \n",
       "4                                 Drama | Romance   \n",
       "\n",
       "                    cld_production_countries  \\\n",
       "0                   United States of America   \n",
       "1  United Kingdom | United States of America   \n",
       "2                   United States of America   \n",
       "3                   United States of America   \n",
       "4                   United States of America   \n",
       "\n",
       "                            cld_production_companies  \\\n",
       "0                                     Marvel Studios   \n",
       "1  20th Century Fox | Dune Entertainment | Ingeni...   \n",
       "2                         Bad Robot | Lucasfilm Ltd.   \n",
       "3                                     Marvel Studios   \n",
       "4  20th Century Fox | Lightstorm Entertainment | ...   \n",
       "\n",
       "                                                crew  \n",
       "0  Paul Schneider | Louis D'Esposito | Carlos Pac...  \n",
       "1  James Cameron | James Cameron | Ilram Choi | W...  \n",
       "2  Ron Jones | J.J. Abrams | Bryan Burk | J.J. Ab...  \n",
       "3  Paul Schneider | John David Duncan | Jwaundace...  \n",
       "4  James Cameron | Sharon Mann | Emily Schweber |...  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List of columns new order \n",
    "new_order =['id', 'title', 'tagline', 'release_date', 'genres', 'belongs_to_collection', \n",
    "            'original_language', 'budget_musd', 'revenue_musd', 'production_companies', 'production_countries', \n",
    "            'vote_count', 'vote_average', 'popularity', 'runtime', 'overview',\n",
    "            'spoken_languages', 'poster_path', 'cast', 'cast_size', 'director', 'crew_size']\n",
    "\n",
    "# Reorder DataFrame\n",
    "reordered_df = df[new_order]\n",
    "path=\"/Users/gyauk/github/labs/IMBD_movie_analysis/Project1/data/processed/reordered_movies.csv\"\n",
    "dcp.reorder_and_save(df,new_order,path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'title', 'tagline', 'release_date', 'genres',\n",
       "       'belongs_to_collection', 'original_language', 'budget_musd',\n",
       "       'revenue_musd', 'production_companies', 'production_countries',\n",
       "       'vote_count', 'vote_average', 'popularity', 'runtime', 'overview',\n",
       "       'spoken_languages', 'poster_path', 'cast', 'cast_size', 'director',\n",
       "       'crew_size'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reordered_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KPI Implementation & Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- highest revenue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avatar generated the most revenue of USD 2923.71\n"
     ]
    }
   ],
   "source": [
    "kpi.highest_revenue_movie(reordered_df,'title','revenue_musd')\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Highest Budget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avatar had the highest budget of USD 2923.71\n"
     ]
    }
   ],
   "source": [
    "kpi.highest_budget_movie(reordered_df,'title','revenue_musd')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Highest Profit (Revenue - Budget)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avatar had the highest profit of USD 2686.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gyauk/github/labs/IMBD_movie_analysis/Project1/src/kpi_analysis.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[profit_column] = df[revenue_column] - df[budget_column]\n"
     ]
    }
   ],
   "source": [
    "kpi.highest_profit_movie(reordered_df,'title','revenue_musd','budget_musd','profit')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Lowest Profit (Revenue - Budget)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avengers: Age of Ultron had the lowest profit of USD 1040.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gyauk/github/labs/IMBD_movie_analysis/Project1/src/kpi_analysis.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[profit_column] = df[revenue_column] - df[budget_column]\n"
     ]
    }
   ],
   "source": [
    "kpi.lowest_profit_movie(reordered_df,'title','revenue_musd','budget_musd','profit')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Highest ROI (Revenue / Budget) (only movies with Budget ≥ 10M) o Lowest ROI (only movies with Budget ≥ 10M)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avatar had the highest ROI of 12.336329113924052\n"
     ]
    }
   ],
   "source": [
    "kpi.highest_roi(reordered_df,'title','revenue_musd','budget_musd','roi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avengers: Age of Ultron had the lowest ROI of 3.85041095890411\n"
     ]
    }
   ],
   "source": [
    " kpi.lowest_roi(reordered_df,'title','revenue_musd','budget_musd','roi')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Most Voted Movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avatar was the most voted movie with 32121 votes.\n"
     ]
    }
   ],
   "source": [
    "kpi.most_voted(reordered_df,'title','vote_count')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Highest Rated Movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avengers: Endgame was the highest rated movie with a rating of 8.238\n"
     ]
    }
   ],
   "source": [
    "kpi.highest_rated(reordered_df,'title','vote_count','vote_average')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Lowest Rated Movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jurassic World: Fallen Kingdom was the lowest rated movie with a rating of 6.538\n"
     ]
    }
   ],
   "source": [
    "kpi.lowest_rated(reordered_df,'title','vote_count','vote_average')    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Most Popular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Titanic was the most popular movie with a popularity score of 38.6063\n"
     ]
    }
   ],
   "source": [
    "kpi.most_popular(reordered_df,'title','popularity')    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Advanced Movie Filtering & Search Queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Search 1: Find the best-rated Science Fiction Action movies starring Bruce Willis (sorted by Rating - highest to lowest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>vote_average</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Avengers: Endgame</td>\n",
       "      <td>8.238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Avengers: Infinity War</td>\n",
       "      <td>8.236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>The Avengers</td>\n",
       "      <td>7.735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Avengers: Age of Ultron</td>\n",
       "      <td>7.271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Star Wars: The Force Awakens</td>\n",
       "      <td>7.262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Furious 7</td>\n",
       "      <td>7.200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Jurassic World: Fallen Kingdom</td>\n",
       "      <td>6.538</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             title  vote_average\n",
       "0                Avengers: Endgame         8.238\n",
       "3           Avengers: Infinity War         8.236\n",
       "7                     The Avengers         7.735\n",
       "9          Avengers: Age of Ultron         7.271\n",
       "2     Star Wars: The Force Awakens         7.262\n",
       "8                        Furious 7         7.200\n",
       "14  Jurassic World: Fallen Kingdom         6.538"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#filter by science fiction first \n",
    "specific_genres = ['Science Fiction', 'Action']\n",
    "filtered_genre_df = reordered_df[reordered_df['genres'].apply(lambda genres: any(genre['name'] in specific_genres for genre in genres))]\n",
    "filtered_genre_df\n",
    "\n",
    "#fileter by actor bruce willis\n",
    "filter_actor_df=filtered_genre_df[filtered_genre_df['cast'].apply(lambda cast: 'Robert' in cast)]\n",
    "filter_actor_df\n",
    "\n",
    "# Sort by the 'vote_average' column (rating) in descending order\n",
    "sorted_movies = filter_actor_df.sort_values(by='vote_average', ascending=False)\n",
    "\n",
    "# Select relevant columns to display\n",
    "best_rated_movies = sorted_movies[['title', 'vote_average']]\n",
    "\n",
    "# Display the best-rated movies\n",
    "best_rated_movies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Search 2: Find movies starring Uma Thurman, directed by Quentin Tarantino (sorted by runtime - shortest to longest)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Franchise vs. Standalone Movie Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>backdrop_path</th>\n",
       "      <th>belongs_to_collection</th>\n",
       "      <th>genres</th>\n",
       "      <th>id</th>\n",
       "      <th>origin_country</th>\n",
       "      <th>original_language</th>\n",
       "      <th>overview</th>\n",
       "      <th>popularity</th>\n",
       "      <th>poster_path</th>\n",
       "      <th>production_companies</th>\n",
       "      <th>...</th>\n",
       "      <th>cld_production_countries</th>\n",
       "      <th>cld_production_companies</th>\n",
       "      <th>cast</th>\n",
       "      <th>crew</th>\n",
       "      <th>director</th>\n",
       "      <th>cast_size</th>\n",
       "      <th>crew_size</th>\n",
       "      <th>budget_musd</th>\n",
       "      <th>revenue_musd</th>\n",
       "      <th>is_franchise</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/7RyHsO4yDXtBv1zUU3mTpHeQ0d5.jpg</td>\n",
       "      <td>{'id': 86311, 'name': 'The Avengers Collection...</td>\n",
       "      <td>[{'id': 12, 'name': 'Adventure'}, {'id': 878, ...</td>\n",
       "      <td>299534</td>\n",
       "      <td>['US']</td>\n",
       "      <td>| English | 日本語</td>\n",
       "      <td>After the devastating events of Avengers: Infi...</td>\n",
       "      <td>24.2346</td>\n",
       "      <td>/ulzhLuWrPK07P1YkdWQLZnQh1JL.jpg</td>\n",
       "      <td>[{'id': 420, 'logo_path': '/hUzeosd33nzE5MCNsZ...</td>\n",
       "      <td>...</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>Marvel Studios</td>\n",
       "      <td>Robert Downey Jr. | Chris Evans | Mark Ruffalo...</td>\n",
       "      <td>Paul Schneider | Louis D'Esposito | Carlos Pac...</td>\n",
       "      <td>Anthony Russo</td>\n",
       "      <td>105</td>\n",
       "      <td>593</td>\n",
       "      <td>356.0</td>\n",
       "      <td>2799.44</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/vL5LR6WdxWPjLPFRLe133jXWsh5.jpg</td>\n",
       "      <td>{'id': 87096, 'name': 'Avatar Collection', 'po...</td>\n",
       "      <td>[{'id': 28, 'name': 'Action'}, {'id': 12, 'nam...</td>\n",
       "      <td>19995</td>\n",
       "      <td>['US']</td>\n",
       "      <td>English | Español</td>\n",
       "      <td>In the 22nd century, a paraplegic Marine is di...</td>\n",
       "      <td>32.6950</td>\n",
       "      <td>/kyeqWdyUXW608qlYkRqosgbbJyK.jpg</td>\n",
       "      <td>[{'id': 444, 'logo_path': None, 'name': 'Dune ...</td>\n",
       "      <td>...</td>\n",
       "      <td>United Kingdom | United States of America</td>\n",
       "      <td>20th Century Fox | Dune Entertainment | Ingeni...</td>\n",
       "      <td>Sam Worthington | Zoe Saldaña | Sigourney Weav...</td>\n",
       "      <td>James Cameron | James Cameron | Ilram Choi | W...</td>\n",
       "      <td>James Cameron</td>\n",
       "      <td>65</td>\n",
       "      <td>986</td>\n",
       "      <td>237.0</td>\n",
       "      <td>2923.71</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/k6EOrckWFuz7I4z4wiRwz8zsj4H.jpg</td>\n",
       "      <td>{'id': 10, 'name': 'Star Wars Collection', 'po...</td>\n",
       "      <td>[{'id': 12, 'name': 'Adventure'}, {'id': 28, '...</td>\n",
       "      <td>140607</td>\n",
       "      <td>['US']</td>\n",
       "      <td>English</td>\n",
       "      <td>Thirty years after defeating the Galactic Empi...</td>\n",
       "      <td>13.1664</td>\n",
       "      <td>/wqnLdwVXoBjKibFRR5U3y0aDUhs.jpg</td>\n",
       "      <td>[{'id': 1, 'logo_path': '/tlVSws0RvvtPBwViUyOF...</td>\n",
       "      <td>...</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>Bad Robot | Lucasfilm Ltd.</td>\n",
       "      <td>Harrison Ford | Mark Hamill | Carrie Fisher | ...</td>\n",
       "      <td>Ron Jones | J.J. Abrams | Bryan Burk | J.J. Ab...</td>\n",
       "      <td>J.J. Abrams</td>\n",
       "      <td>182</td>\n",
       "      <td>257</td>\n",
       "      <td>245.0</td>\n",
       "      <td>2068.22</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/mDfJG3LC3Dqb67AZ52x3Z0jU0uB.jpg</td>\n",
       "      <td>{'id': 86311, 'name': 'The Avengers Collection...</td>\n",
       "      <td>[{'id': 12, 'name': 'Adventure'}, {'id': 28, '...</td>\n",
       "      <td>299536</td>\n",
       "      <td>['US']</td>\n",
       "      <td>| English</td>\n",
       "      <td>As the Avengers and their allies have continue...</td>\n",
       "      <td>33.0700</td>\n",
       "      <td>/7WsyChQLEftFiDOVTGkv3hFpyyt.jpg</td>\n",
       "      <td>[{'id': 420, 'logo_path': '/hUzeosd33nzE5MCNsZ...</td>\n",
       "      <td>...</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>Marvel Studios</td>\n",
       "      <td>Robert Downey Jr. | Chris Evans | Chris Hemswo...</td>\n",
       "      <td>Paul Schneider | John David Duncan | Jwaundace...</td>\n",
       "      <td>Joe Russo</td>\n",
       "      <td>69</td>\n",
       "      <td>724</td>\n",
       "      <td>300.0</td>\n",
       "      <td>2052.42</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/sCzcYW9h55WcesOqA12cgEr9Exw.jpg</td>\n",
       "      <td>{}</td>\n",
       "      <td>[{'id': 18, 'name': 'Drama'}, {'id': 10749, 'n...</td>\n",
       "      <td>597</td>\n",
       "      <td>['US']</td>\n",
       "      <td>Deutsch | English | Français | Italiano | Pусс...</td>\n",
       "      <td>101-year-old Rose DeWitt Bukater tells the sto...</td>\n",
       "      <td>38.6063</td>\n",
       "      <td>/9xjZS2rlVxm8SFx8kPC3aIGCOYQ.jpg</td>\n",
       "      <td>[{'id': 4, 'logo_path': '/gz66EfNoYPqHTYI4q9UE...</td>\n",
       "      <td>...</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>20th Century Fox | Lightstorm Entertainment | ...</td>\n",
       "      <td>Leonardo DiCaprio | Kate Winslet | Billy Zane ...</td>\n",
       "      <td>James Cameron | Sharon Mann | Emily Schweber |...</td>\n",
       "      <td>James Cameron</td>\n",
       "      <td>116</td>\n",
       "      <td>258</td>\n",
       "      <td>200.0</td>\n",
       "      <td>2264.16</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      backdrop_path  \\\n",
       "0  /7RyHsO4yDXtBv1zUU3mTpHeQ0d5.jpg   \n",
       "1  /vL5LR6WdxWPjLPFRLe133jXWsh5.jpg   \n",
       "2  /k6EOrckWFuz7I4z4wiRwz8zsj4H.jpg   \n",
       "3  /mDfJG3LC3Dqb67AZ52x3Z0jU0uB.jpg   \n",
       "4  /sCzcYW9h55WcesOqA12cgEr9Exw.jpg   \n",
       "\n",
       "                               belongs_to_collection  \\\n",
       "0  {'id': 86311, 'name': 'The Avengers Collection...   \n",
       "1  {'id': 87096, 'name': 'Avatar Collection', 'po...   \n",
       "2  {'id': 10, 'name': 'Star Wars Collection', 'po...   \n",
       "3  {'id': 86311, 'name': 'The Avengers Collection...   \n",
       "4                                                 {}   \n",
       "\n",
       "                                              genres      id origin_country  \\\n",
       "0  [{'id': 12, 'name': 'Adventure'}, {'id': 878, ...  299534         ['US']   \n",
       "1  [{'id': 28, 'name': 'Action'}, {'id': 12, 'nam...   19995         ['US']   \n",
       "2  [{'id': 12, 'name': 'Adventure'}, {'id': 28, '...  140607         ['US']   \n",
       "3  [{'id': 12, 'name': 'Adventure'}, {'id': 28, '...  299536         ['US']   \n",
       "4  [{'id': 18, 'name': 'Drama'}, {'id': 10749, 'n...     597         ['US']   \n",
       "\n",
       "                                   original_language  \\\n",
       "0                                    | English | 日本語   \n",
       "1                                  English | Español   \n",
       "2                                            English   \n",
       "3                                          | English   \n",
       "4  Deutsch | English | Français | Italiano | Pусс...   \n",
       "\n",
       "                                            overview  popularity  \\\n",
       "0  After the devastating events of Avengers: Infi...     24.2346   \n",
       "1  In the 22nd century, a paraplegic Marine is di...     32.6950   \n",
       "2  Thirty years after defeating the Galactic Empi...     13.1664   \n",
       "3  As the Avengers and their allies have continue...     33.0700   \n",
       "4  101-year-old Rose DeWitt Bukater tells the sto...     38.6063   \n",
       "\n",
       "                        poster_path  \\\n",
       "0  /ulzhLuWrPK07P1YkdWQLZnQh1JL.jpg   \n",
       "1  /kyeqWdyUXW608qlYkRqosgbbJyK.jpg   \n",
       "2  /wqnLdwVXoBjKibFRR5U3y0aDUhs.jpg   \n",
       "3  /7WsyChQLEftFiDOVTGkv3hFpyyt.jpg   \n",
       "4  /9xjZS2rlVxm8SFx8kPC3aIGCOYQ.jpg   \n",
       "\n",
       "                                production_companies  ...  \\\n",
       "0  [{'id': 420, 'logo_path': '/hUzeosd33nzE5MCNsZ...  ...   \n",
       "1  [{'id': 444, 'logo_path': None, 'name': 'Dune ...  ...   \n",
       "2  [{'id': 1, 'logo_path': '/tlVSws0RvvtPBwViUyOF...  ...   \n",
       "3  [{'id': 420, 'logo_path': '/hUzeosd33nzE5MCNsZ...  ...   \n",
       "4  [{'id': 4, 'logo_path': '/gz66EfNoYPqHTYI4q9UE...  ...   \n",
       "\n",
       "                    cld_production_countries  \\\n",
       "0                   United States of America   \n",
       "1  United Kingdom | United States of America   \n",
       "2                   United States of America   \n",
       "3                   United States of America   \n",
       "4                   United States of America   \n",
       "\n",
       "                            cld_production_companies  \\\n",
       "0                                     Marvel Studios   \n",
       "1  20th Century Fox | Dune Entertainment | Ingeni...   \n",
       "2                         Bad Robot | Lucasfilm Ltd.   \n",
       "3                                     Marvel Studios   \n",
       "4  20th Century Fox | Lightstorm Entertainment | ...   \n",
       "\n",
       "                                                cast  \\\n",
       "0  Robert Downey Jr. | Chris Evans | Mark Ruffalo...   \n",
       "1  Sam Worthington | Zoe Saldaña | Sigourney Weav...   \n",
       "2  Harrison Ford | Mark Hamill | Carrie Fisher | ...   \n",
       "3  Robert Downey Jr. | Chris Evans | Chris Hemswo...   \n",
       "4  Leonardo DiCaprio | Kate Winslet | Billy Zane ...   \n",
       "\n",
       "                                                crew       director cast_size  \\\n",
       "0  Paul Schneider | Louis D'Esposito | Carlos Pac...  Anthony Russo       105   \n",
       "1  James Cameron | James Cameron | Ilram Choi | W...  James Cameron        65   \n",
       "2  Ron Jones | J.J. Abrams | Bryan Burk | J.J. Ab...    J.J. Abrams       182   \n",
       "3  Paul Schneider | John David Duncan | Jwaundace...      Joe Russo        69   \n",
       "4  James Cameron | Sharon Mann | Emily Schweber |...  James Cameron       116   \n",
       "\n",
       "  crew_size  budget_musd  revenue_musd is_franchise  \n",
       "0       593        356.0       2799.44         True  \n",
       "1       986        237.0       2923.71         True  \n",
       "2       257        245.0       2068.22         True  \n",
       "3       724        300.0       2052.42         True  \n",
       "4       258        200.0       2264.16        False  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "franch.add_is_franchise_column(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- mean revenue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Is_Franchise</th>\n",
       "      <th>Mean_Revenue_musd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Standalone</td>\n",
       "      <td>1765.140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Franchise</td>\n",
       "      <td>1682.643125</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Is_Franchise  Mean_Revenue_musd\n",
       "0   Standalone        1765.140000\n",
       "1    Franchise        1682.643125"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "franch.mean_revenue_by_franchise(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Median ROI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Is_Franchise</th>\n",
       "      <th>Median_ROI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Standalone</td>\n",
       "      <td>9.617025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Franchise</td>\n",
       "      <td>7.786121</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Is_Franchise  Median_ROI\n",
       "0   Standalone    9.617025\n",
       "1    Franchise    7.786121"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "franch.median_roi_by_franchise(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mean Popularity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Is_Franchise</th>\n",
       "      <th>Mean_Popularity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Standalone</td>\n",
       "      <td>28.162750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Franchise</td>\n",
       "      <td>19.622387</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Is_Franchise  Mean_Popularity\n",
       "0   Standalone        28.162750\n",
       "1    Franchise        19.622387"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "franch.mean_popularity_by_franchise(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mean budget raised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Is_Franchise</th>\n",
       "      <th>Mean_Vote_Average</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Standalone</td>\n",
       "      <td>7.438000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Franchise</td>\n",
       "      <td>7.379625</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Is_Franchise  Mean_Vote_Average\n",
       "0   Standalone           7.438000\n",
       "1    Franchise           7.379625"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "franch.mean_rating_by_franchise(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Franchise Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>collection_name</th>\n",
       "      <th>movie_count</th>\n",
       "      <th>total_budget</th>\n",
       "      <th>mean_budget</th>\n",
       "      <th>total_revenue</th>\n",
       "      <th>mean_revenue</th>\n",
       "      <th>mean_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Avatar Collection</td>\n",
       "      <td>1</td>\n",
       "      <td>237.0</td>\n",
       "      <td>237.00</td>\n",
       "      <td>2923.71</td>\n",
       "      <td>2923.710</td>\n",
       "      <td>7.5880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Black Panther Collection</td>\n",
       "      <td>1</td>\n",
       "      <td>200.0</td>\n",
       "      <td>200.00</td>\n",
       "      <td>1349.93</td>\n",
       "      <td>1349.930</td>\n",
       "      <td>7.3730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Frozen Collection</td>\n",
       "      <td>2</td>\n",
       "      <td>300.0</td>\n",
       "      <td>150.00</td>\n",
       "      <td>2727.90</td>\n",
       "      <td>1363.950</td>\n",
       "      <td>7.2485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Harry Potter Collection</td>\n",
       "      <td>1</td>\n",
       "      <td>125.0</td>\n",
       "      <td>125.00</td>\n",
       "      <td>1341.51</td>\n",
       "      <td>1341.510</td>\n",
       "      <td>8.1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Jurassic Park Collection</td>\n",
       "      <td>2</td>\n",
       "      <td>320.0</td>\n",
       "      <td>160.00</td>\n",
       "      <td>2982.01</td>\n",
       "      <td>1491.005</td>\n",
       "      <td>6.6155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Star Wars Collection</td>\n",
       "      <td>2</td>\n",
       "      <td>445.0</td>\n",
       "      <td>222.50</td>\n",
       "      <td>3400.92</td>\n",
       "      <td>1700.460</td>\n",
       "      <td>7.0210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>The Avengers Collection</td>\n",
       "      <td>4</td>\n",
       "      <td>1241.0</td>\n",
       "      <td>310.25</td>\n",
       "      <td>7776.08</td>\n",
       "      <td>1944.020</td>\n",
       "      <td>7.8700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>The Fast and the Furious Collection</td>\n",
       "      <td>1</td>\n",
       "      <td>190.0</td>\n",
       "      <td>190.00</td>\n",
       "      <td>1515.40</td>\n",
       "      <td>1515.400</td>\n",
       "      <td>7.2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>The Incredibles Collection</td>\n",
       "      <td>1</td>\n",
       "      <td>200.0</td>\n",
       "      <td>200.00</td>\n",
       "      <td>1242.81</td>\n",
       "      <td>1242.810</td>\n",
       "      <td>7.4540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>The Lion King (Reboot) Collection</td>\n",
       "      <td>1</td>\n",
       "      <td>260.0</td>\n",
       "      <td>260.00</td>\n",
       "      <td>1662.02</td>\n",
       "      <td>1662.020</td>\n",
       "      <td>7.1090</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       collection_name  movie_count  total_budget  \\\n",
       "0                    Avatar Collection            1         237.0   \n",
       "1             Black Panther Collection            1         200.0   \n",
       "2                    Frozen Collection            2         300.0   \n",
       "3              Harry Potter Collection            1         125.0   \n",
       "4             Jurassic Park Collection            2         320.0   \n",
       "5                 Star Wars Collection            2         445.0   \n",
       "6              The Avengers Collection            4        1241.0   \n",
       "7  The Fast and the Furious Collection            1         190.0   \n",
       "8           The Incredibles Collection            1         200.0   \n",
       "9    The Lion King (Reboot) Collection            1         260.0   \n",
       "\n",
       "   mean_budget  total_revenue  mean_revenue  mean_rating  \n",
       "0       237.00        2923.71      2923.710       7.5880  \n",
       "1       200.00        1349.93      1349.930       7.3730  \n",
       "2       150.00        2727.90      1363.950       7.2485  \n",
       "3       125.00        1341.51      1341.510       8.1000  \n",
       "4       160.00        2982.01      1491.005       6.6155  \n",
       "5       222.50        3400.92      1700.460       7.0210  \n",
       "6       310.25        7776.08      1944.020       7.8700  \n",
       "7       190.00        1515.40      1515.400       7.2000  \n",
       "8       200.00        1242.81      1242.810       7.4540  \n",
       "9       260.00        1662.02      1662.020       7.1090  "
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "franch.generate_franchise_summary(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Most Successful Franchises & Directors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>collection_name</th>\n",
       "      <th>movie_count</th>\n",
       "      <th>total_budget</th>\n",
       "      <th>mean_budget</th>\n",
       "      <th>total_revenue</th>\n",
       "      <th>mean_revenue</th>\n",
       "      <th>mean_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Avatar Collection</td>\n",
       "      <td>1</td>\n",
       "      <td>237.0</td>\n",
       "      <td>237.00</td>\n",
       "      <td>2923.71</td>\n",
       "      <td>2923.710</td>\n",
       "      <td>7.5880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Black Panther Collection</td>\n",
       "      <td>1</td>\n",
       "      <td>200.0</td>\n",
       "      <td>200.00</td>\n",
       "      <td>1349.93</td>\n",
       "      <td>1349.930</td>\n",
       "      <td>7.3730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Frozen Collection</td>\n",
       "      <td>2</td>\n",
       "      <td>300.0</td>\n",
       "      <td>150.00</td>\n",
       "      <td>2727.90</td>\n",
       "      <td>1363.950</td>\n",
       "      <td>7.2485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Harry Potter Collection</td>\n",
       "      <td>1</td>\n",
       "      <td>125.0</td>\n",
       "      <td>125.00</td>\n",
       "      <td>1341.51</td>\n",
       "      <td>1341.510</td>\n",
       "      <td>8.1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Jurassic Park Collection</td>\n",
       "      <td>2</td>\n",
       "      <td>320.0</td>\n",
       "      <td>160.00</td>\n",
       "      <td>2982.01</td>\n",
       "      <td>1491.005</td>\n",
       "      <td>6.6155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Star Wars Collection</td>\n",
       "      <td>2</td>\n",
       "      <td>445.0</td>\n",
       "      <td>222.50</td>\n",
       "      <td>3400.92</td>\n",
       "      <td>1700.460</td>\n",
       "      <td>7.0210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>The Avengers Collection</td>\n",
       "      <td>4</td>\n",
       "      <td>1241.0</td>\n",
       "      <td>310.25</td>\n",
       "      <td>7776.08</td>\n",
       "      <td>1944.020</td>\n",
       "      <td>7.8700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>The Fast and the Furious Collection</td>\n",
       "      <td>1</td>\n",
       "      <td>190.0</td>\n",
       "      <td>190.00</td>\n",
       "      <td>1515.40</td>\n",
       "      <td>1515.400</td>\n",
       "      <td>7.2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>The Incredibles Collection</td>\n",
       "      <td>1</td>\n",
       "      <td>200.0</td>\n",
       "      <td>200.00</td>\n",
       "      <td>1242.81</td>\n",
       "      <td>1242.810</td>\n",
       "      <td>7.4540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>The Lion King (Reboot) Collection</td>\n",
       "      <td>1</td>\n",
       "      <td>260.0</td>\n",
       "      <td>260.00</td>\n",
       "      <td>1662.02</td>\n",
       "      <td>1662.020</td>\n",
       "      <td>7.1090</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       collection_name  movie_count  total_budget  \\\n",
       "0                    Avatar Collection            1         237.0   \n",
       "1             Black Panther Collection            1         200.0   \n",
       "2                    Frozen Collection            2         300.0   \n",
       "3              Harry Potter Collection            1         125.0   \n",
       "4             Jurassic Park Collection            2         320.0   \n",
       "5                 Star Wars Collection            2         445.0   \n",
       "6              The Avengers Collection            4        1241.0   \n",
       "7  The Fast and the Furious Collection            1         190.0   \n",
       "8           The Incredibles Collection            1         200.0   \n",
       "9    The Lion King (Reboot) Collection            1         260.0   \n",
       "\n",
       "   mean_budget  total_revenue  mean_revenue  mean_rating  \n",
       "0       237.00        2923.71      2923.710       7.5880  \n",
       "1       200.00        1349.93      1349.930       7.3730  \n",
       "2       150.00        2727.90      1363.950       7.2485  \n",
       "3       125.00        1341.51      1341.510       8.1000  \n",
       "4       160.00        2982.01      1491.005       6.6155  \n",
       "5       222.50        3400.92      1700.460       7.0210  \n",
       "6       310.25        7776.08      1944.020       7.8700  \n",
       "7       190.00        1515.40      1515.400       7.2000  \n",
       "8       200.00        1242.81      1242.810       7.4540  \n",
       "9       260.00        1662.02      1662.020       7.1090  "
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "franchise_summary = franch.generate_franchise_summary(df)\n",
    "franchise_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With a mean budget of 310.25 ,The Avengers Collection is the most sucessful movie franschise\n"
     ]
    }
   ],
   "source": [
    "franch.sort_mean_budget(franchise_summary,'collection_name','mean_budget')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With a  total budget of  1241.0, The Avengers Collection is the most sucessful movie franschise\n"
     ]
    }
   ],
   "source": [
    "franch.sort_total_budget(franchise_summary,'collection_name','total_budget')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With a total revenue of  7776.08,The Avengers Collection is the most sucessful movie franschise\n"
     ]
    }
   ],
   "source": [
    "franch.sort_total_revenue(franchise_summary,'collection_name','total_revenue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With a mean revenue of  2923.71 ,Avatar Collection is the most sucessful movie franschise\n"
     ]
    }
   ],
   "source": [
    "franch.sort_mean_revenue(franchise_summary,'collection_name','mean_revenue')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With a mean rating of  8.1 ,Harry Potter Collection is the most sucessful movie franschise\n"
     ]
    }
   ],
   "source": [
    "franch.sort_mean_rating(franchise_summary,'collection_name','mean_rating')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Avengers Collection is the most successful movie franchise with  4 movie franchises.\n"
     ]
    }
   ],
   "source": [
    "franch.sort_most_successful_movieinfranchise(franchise_summary,'collection_name','movie_count')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>director</th>\n",
       "      <th>num_movies_directed</th>\n",
       "      <th>total_revenue</th>\n",
       "      <th>mean_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Anthony Russo</td>\n",
       "      <td>1</td>\n",
       "      <td>2799.44</td>\n",
       "      <td>8.2380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bill Condon</td>\n",
       "      <td>1</td>\n",
       "      <td>1266.12</td>\n",
       "      <td>6.9710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Brad Bird</td>\n",
       "      <td>1</td>\n",
       "      <td>1242.81</td>\n",
       "      <td>7.4540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Colin Trevorrow</td>\n",
       "      <td>1</td>\n",
       "      <td>1671.54</td>\n",
       "      <td>6.6930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>David Yates</td>\n",
       "      <td>1</td>\n",
       "      <td>1341.51</td>\n",
       "      <td>8.1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>J.A. Bayona</td>\n",
       "      <td>1</td>\n",
       "      <td>1310.47</td>\n",
       "      <td>6.5380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>J.J. Abrams</td>\n",
       "      <td>1</td>\n",
       "      <td>2068.22</td>\n",
       "      <td>7.2620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>James Cameron</td>\n",
       "      <td>2</td>\n",
       "      <td>5187.87</td>\n",
       "      <td>7.7465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>James Wan</td>\n",
       "      <td>1</td>\n",
       "      <td>1515.40</td>\n",
       "      <td>7.2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Jennifer Lee</td>\n",
       "      <td>2</td>\n",
       "      <td>2727.90</td>\n",
       "      <td>7.2485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Joe Russo</td>\n",
       "      <td>1</td>\n",
       "      <td>2052.42</td>\n",
       "      <td>8.2360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Jon Favreau</td>\n",
       "      <td>1</td>\n",
       "      <td>1662.02</td>\n",
       "      <td>7.1090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Joss Whedon</td>\n",
       "      <td>2</td>\n",
       "      <td>2924.22</td>\n",
       "      <td>7.5030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Rian Johnson</td>\n",
       "      <td>1</td>\n",
       "      <td>1332.70</td>\n",
       "      <td>6.7800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Ryan Coogler</td>\n",
       "      <td>1</td>\n",
       "      <td>1349.93</td>\n",
       "      <td>7.3730</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           director  num_movies_directed  total_revenue  mean_rating\n",
       "0     Anthony Russo                    1        2799.44       8.2380\n",
       "1       Bill Condon                    1        1266.12       6.9710\n",
       "2         Brad Bird                    1        1242.81       7.4540\n",
       "3   Colin Trevorrow                    1        1671.54       6.6930\n",
       "4       David Yates                    1        1341.51       8.1000\n",
       "5       J.A. Bayona                    1        1310.47       6.5380\n",
       "6       J.J. Abrams                    1        2068.22       7.2620\n",
       "7     James Cameron                    2        5187.87       7.7465\n",
       "8         James Wan                    1        1515.40       7.2000\n",
       "9      Jennifer Lee                    2        2727.90       7.2485\n",
       "10        Joe Russo                    1        2052.42       8.2360\n",
       "11      Jon Favreau                    1        1662.02       7.1090\n",
       "12      Joss Whedon                    2        2924.22       7.5030\n",
       "13     Rian Johnson                    1        1332.70       6.7800\n",
       "14     Ryan Coogler                    1        1349.93       7.3730"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "franch.generate_director_df(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>director</th>\n",
       "      <th>num_movies_directed</th>\n",
       "      <th>total_revenue</th>\n",
       "      <th>mean_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Anthony Russo</td>\n",
       "      <td>1</td>\n",
       "      <td>2799.44</td>\n",
       "      <td>8.2380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bill Condon</td>\n",
       "      <td>1</td>\n",
       "      <td>1266.12</td>\n",
       "      <td>6.9710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Brad Bird</td>\n",
       "      <td>1</td>\n",
       "      <td>1242.81</td>\n",
       "      <td>7.4540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Colin Trevorrow</td>\n",
       "      <td>1</td>\n",
       "      <td>1671.54</td>\n",
       "      <td>6.6930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>David Yates</td>\n",
       "      <td>1</td>\n",
       "      <td>1341.51</td>\n",
       "      <td>8.1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>J.A. Bayona</td>\n",
       "      <td>1</td>\n",
       "      <td>1310.47</td>\n",
       "      <td>6.5380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>J.J. Abrams</td>\n",
       "      <td>1</td>\n",
       "      <td>2068.22</td>\n",
       "      <td>7.2620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>James Cameron</td>\n",
       "      <td>2</td>\n",
       "      <td>5187.87</td>\n",
       "      <td>7.7465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>James Wan</td>\n",
       "      <td>1</td>\n",
       "      <td>1515.40</td>\n",
       "      <td>7.2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Jennifer Lee</td>\n",
       "      <td>2</td>\n",
       "      <td>2727.90</td>\n",
       "      <td>7.2485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Joe Russo</td>\n",
       "      <td>1</td>\n",
       "      <td>2052.42</td>\n",
       "      <td>8.2360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Jon Favreau</td>\n",
       "      <td>1</td>\n",
       "      <td>1662.02</td>\n",
       "      <td>7.1090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Joss Whedon</td>\n",
       "      <td>2</td>\n",
       "      <td>2924.22</td>\n",
       "      <td>7.5030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Rian Johnson</td>\n",
       "      <td>1</td>\n",
       "      <td>1332.70</td>\n",
       "      <td>6.7800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Ryan Coogler</td>\n",
       "      <td>1</td>\n",
       "      <td>1349.93</td>\n",
       "      <td>7.3730</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           director  num_movies_directed  total_revenue  mean_rating\n",
       "0     Anthony Russo                    1        2799.44       8.2380\n",
       "1       Bill Condon                    1        1266.12       6.9710\n",
       "2         Brad Bird                    1        1242.81       7.4540\n",
       "3   Colin Trevorrow                    1        1671.54       6.6930\n",
       "4       David Yates                    1        1341.51       8.1000\n",
       "5       J.A. Bayona                    1        1310.47       6.5380\n",
       "6       J.J. Abrams                    1        2068.22       7.2620\n",
       "7     James Cameron                    2        5187.87       7.7465\n",
       "8         James Wan                    1        1515.40       7.2000\n",
       "9      Jennifer Lee                    2        2727.90       7.2485\n",
       "10        Joe Russo                    1        2052.42       8.2360\n",
       "11      Jon Favreau                    1        1662.02       7.1090\n",
       "12      Joss Whedon                    2        2924.22       7.5030\n",
       "13     Rian Johnson                    1        1332.70       6.7800\n",
       "14     Ryan Coogler                    1        1349.93       7.3730"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# franch.generate_director_df(reordered_df)\n",
    "director_df= franch.generate_director_df(df)\n",
    "director_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joss Whedon has directed 2 movies.\n"
     ]
    }
   ],
   "source": [
    "franch.most_movies_directed(director_df,'director','num_movies_directed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "James Cameron is the most successful by generating USD 5187.87 in revenue.\n"
     ]
    }
   ],
   "source": [
    "franch.most_successful_director_by_revenue(director_df,'director','total_revenue')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anthony Russo is the most successful by having a mean rating of 8.238.\n"
     ]
    }
   ],
   "source": [
    "franch.successful_director_meanrating(director_df,'director','mean_rating')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Revenue vs. Budget Trends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "visn.revenue_vs_budget(reordered_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ROI Distribution by Genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 3000x1500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "visn.roi_distribution_by_genre(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Popularity vs. Rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "visn.popularity_vs_rating(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Yearly Trends in Box Office Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "visn.yearly_box_office_performance(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Comparison of Franchise vs. Standalone Success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "visn.franchise_vs_standalone_success(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vscodeenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
