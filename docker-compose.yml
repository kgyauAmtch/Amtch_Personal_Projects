# version: "3.8" # Specify the version of Docker Compose to use

services:

  zookeeper:
    image: bitnami/zookeeper:latest
    container_name: zookeeper
    ports:
      - "2181:2181"
    environment:
      - ALLOW_ANONYMOUS_LOGIN=yes
    networks:
      - real_data_network

  kafka:
    image: bitnami/kafka:3.6.1-debian-11-r0  
    container_name: kafka
    ports:
      - "9092:9092"
    environment:
      - KAFKA_BROKER_ID=1
      - KAFKA_ZOOKEEPER_CONNECT=zookeeper:2181
      - KAFKA_LISTENERS=PLAINTEXT://:9092
      - KAFKA_ADVERTISED_LISTENERS=PLAINTEXT://kafka:9092
      - KAFKA_CFG_AUTO_CREATE_TOPICS_ENABLE=true
      - ALLOW_PLAINTEXT_LISTENER=yes
    healthcheck:
      test: ["CMD", "kafka-broker-api-versions.sh", "--bootstrap-server", "kafka:9092"]
      interval: 10s
      retries: 5
      timeout: 5s
    depends_on:
      - zookeeper
    networks:
      - real_data_network

  db:
    container_name: heartbeatdata
    image: postgres:15  # Use Postgres version 15
    restart: always  # Ensure the service restarts automatically if it fails
    environment:
      POSTGRES_USER: proj5kafka  # Custom Postgres username
      POSTGRES_PASSWORD: pass_word    #  password for Postgres
      POSTGRES_DB: heart_rate_db      # Custom default database
      PGSSLMODE: disable
    ports:
      - "5435:5432"  # Map local port 5435 to container's port 5432
    volumes:
      - postgres_data:/var/lib/postgresql/data  # Persistent volume for Postgres data
      - ./db/postgres_setup.sql:/docker-entrypoint-initdb.d/postgres_setup.sql  # Custom init SQL script
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U proj5kafka -d heart_rate_db"]  # Health check to ensure Postgres is ready
      interval: 5s  # Check every 5 seconds
      timeout: 5s   # Timeout after 5 seconds
      retries: 10   # Retry 10 times before marking the service as unhealthy
    networks:
      - real_data_network  # Connect the service to the custom network

 
  kafka_consumer:
    image: python:3.10-slim
    container_name: kafka_consumer
    volumes:
      - ./src:/opt/spark/work-dir
    working_dir: /opt/spark/work-dir
    environment:
      KAFKA_BOOTSTRAP_SERVERS: kafka:9092
      KAFKA_TOPIC: producer_to_consumer
      POSTGRES_HOST: db
      POSTGRES_USER: proj5kafka
      POSTGRES_PASSWORD: pass_word
      POSTGRES_DB: heart_rate_db

    command: >
      sh -c "pip install kafka-python psycopg2-binary && sleep 15 && python kafka_consumer.py" # Install kafka-python and run producer wait for 15 secs before running

    depends_on:
      - kafka
      - db
    networks:
      - real_data_network


  kafka_producer:
    image: python:3.10-slim
    container_name: kafka_producer
    volumes:
      - ./src:/opt/spark/work-dir    # Mount  source code folder
    working_dir: /opt/spark/work-dir
    environment:
      KAFKA_BOOTSTRAP_SERVERS: kafka:9092  # Kafka service name from Docker Compose
      KAFKA_TOPIC: producer_to_consumer
      POSTGRES_HOST: db
      POSTGRES_USER: proj5kafka
      POSTGRES_PASSWORD: pass_word
      POSTGRES_DB: heart_rate_db
    command: >
      sh -c "pip install kafka-python  && sleep 30  &&python kafka_producer.py"  # Install kafka-python and run producer wait for 30 secs before running

    depends_on:
      - kafka
      - kafka_consumer
    networks:
      - real_data_network


  grafana:
    image: grafana/grafana:latest
    ports:
      - "3000:3000"
    volumes:
      - grafana-data:/var/lib/grafana
    depends_on:
      - db
    networks: 
      - real_data_network



volumes:
    grafana-data:
    postgres_data: 


networks:
   real_data_network:
     driver: bridge  # Use the bridge network driver for communication between containers


